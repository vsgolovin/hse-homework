{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "sheet_delimiter": true,
     "type": "MD"
    }
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from lets_plot import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div id=\"KVWuWu\"></div>\n",
       "            <script type=\"text/javascript\" data-lets-plot-script=\"library\">\n",
       "                if(!window.letsPlotCallQueue) {\n",
       "                    window.letsPlotCallQueue = [];\n",
       "                }; \n",
       "                window.letsPlotCall = function(f) {\n",
       "                    window.letsPlotCallQueue.push(f);\n",
       "                };\n",
       "                (function() {\n",
       "                    var script = document.createElement(\"script\");\n",
       "                    script.type = \"text/javascript\";\n",
       "                    script.src = \"https://cdn.jsdelivr.net/gh/JetBrains/lets-plot@v2.3.0/js-package/distr/lets-plot.min.js\";\n",
       "                    script.onload = function() {\n",
       "                        window.letsPlotCall = function(f) {f();};\n",
       "                        window.letsPlotCallQueue.forEach(function(f) {f();});\n",
       "                        window.letsPlotCallQueue = [];\n",
       "                        \n",
       "                    };\n",
       "                    script.onerror = function(event) {\n",
       "                        window.letsPlotCall = function(f) {};    // noop\n",
       "                        window.letsPlotCallQueue = [];\n",
       "                        var div = document.createElement(\"div\");\n",
       "                        div.style.color = 'darkred';\n",
       "                        div.textContent = 'Error loading Lets-Plot JS';\n",
       "                        document.getElementById(\"KVWuWu\").appendChild(div);\n",
       "                    };\n",
       "                    var e = document.getElementById(\"KVWuWu\");\n",
       "                    e.appendChild(script);\n",
       "                })()\n",
       "            </script>\n",
       "            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LetsPlot.setup_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib.figure import Figure\n",
    "from matplotlib.axes import Axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def to_scalar(x, i):\n",
    "    \"\"\"Returns i-th element from an array x if x is array, else returns x\n",
    "Args:\n",
    "    x - input array\n",
    "    i - index to return\n",
    "Returns:\n",
    "    x[i] if x is an array and x else\n",
    "\"\"\"\n",
    "    if isinstance(x, (np.ndarray, list)):\n",
    "        return x[i]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def gradient_checker(J, grad_J, theta, eps=1e-4, rtol=1e-5):\n",
    "    \"\"\"Gradient checker for scalar and vector functions\n",
    "Args:\n",
    "    J - function of theta\n",
    "    grad_J - gradient of function J\n",
    "    theta - the point for which to compute the numerical gradient\n",
    "    eps - step value in numerical gradient\n",
    "    rtol - relative tolerance threshold value\n",
    "Returns:\n",
    "    error message if the relative tolerance is greater for some axis\n",
    "    or \"Gradient check passed\" else\n",
    "\"\"\"\n",
    "    it = np.nditer(theta, flags=['multi_index'], op_flags=['readwrite'])\n",
    "\n",
    "    while not it.finished:\n",
    "        ix = it.multi_index\n",
    "\n",
    "        theta_ = np.array(theta, copy=True)\n",
    "        theta_[ix] += eps\n",
    "        np.random.seed(42)\n",
    "        J1 = J(theta_)\n",
    "\n",
    "        theta_ = np.array(theta, copy=True)\n",
    "        theta_[ix] -= eps\n",
    "        np.random.seed(42)\n",
    "        J2 = J(theta_)\n",
    "\n",
    "        J1 = to_scalar(J1, ix)\n",
    "        J2 = to_scalar(J2, ix)\n",
    "\n",
    "        num_grad = (J1 - J2)/(2*eps)\n",
    "\n",
    "        rel_tol = np.abs(num_grad - grad_J(theta))[ix]/(1. + np.minimum(np.abs(num_grad), np.abs(grad_J(theta)[ix])))\n",
    "\n",
    "        if np.all(rel_tol > rtol):\n",
    "            print(f'Incorrect gradient for the axis {str(ix)}')\n",
    "            return\n",
    "        it.iternext()\n",
    "    print(f'Gradient check passed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def J_theta_global(model, loss_function, theta, idx, x, y):\n",
    "    previous = model.parameters()[idx].copy()\n",
    "    np.copyto(dst=model.parameters()[idx], src=theta)\n",
    "    outputs = model(x)\n",
    "    loss = loss_function(outputs, y)\n",
    "    np.copyto(dst=model.parameters()[idx], src=previous)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def dJ_theta_global(model, loss_function, theta, idx, x):\n",
    "    grad = model.backward(loss_function)[idx] / x.shape[0]\n",
    "    return grad.reshape(theta.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def sigmoid(x,slope=1.0):\n",
    "    return 1.0/(1.0+np.exp(-slope*x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def sigmoid_prime(x,slope=1.0):\n",
    "    return slope*sigmoid(x,slope=slope)*(1.0-sigmoid(x,slope=slope))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed\n"
     ]
    }
   ],
   "source": [
    "z = np.random.normal(size=5)\n",
    "gradient_checker(sigmoid, sigmoid_prime, z, eps=1e-4, rtol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def plot_digit(digit, size=8, caption=None):\n",
    "    digit = digit.reshape(size, size)\n",
    "    digit = (digit - np.min(digit))/(np.max(digit) - np.min(digit))\n",
    "    p = ggplot() + geom_image(image_data=digit) + labs(x='', y='') \\\n",
    "        + theme(axis_line='blank', axis_title='blank', axis_ticks='blank', axis_text='blank')\n",
    "    if caption:\n",
    "        p += ggtitle(caption)\n",
    "    return p;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def gg_confusion_matrix(y, y_hat):\n",
    "    conf_mat = confusion_matrix(y, y_hat)[::-1]\n",
    "    confusion_dat = pd.DataFrame(conf_mat)\n",
    "    observed = confusion_dat.columns.values\n",
    "    actual = confusion_dat.index.values\n",
    "    xx, yy = np.meshgrid(actual, observed)\n",
    "    xx = xx.reshape(-1)\n",
    "    yy = yy.reshape(-1)\n",
    "    zz = conf_mat.reshape(-1)\n",
    "    dat = {'predicted':xx, 'actual':yy[::-1], 'z':zz}\n",
    "    p = ggplot(dat, aes('predicted', 'actual', fill='z')) \\\n",
    "        + geom_raster() \\\n",
    "        + geom_text(aes(label='z'), color='white')\\\n",
    "        + theme(legend_position='none', axis_ticks='blank', axis_line='blank')\\\n",
    "        + ggsize(500, 500) + scale_x_discrete() + scale_y_discrete()\\\n",
    "        + ggtitle('Confusion matrix')\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def f1_score_micro(conf_matrix):\n",
    "    num_tags = conf_matrix.shape[0]\n",
    "    score = 0.\n",
    "    pr, p, r = 0., 0., 0.\n",
    "    for tag in range(num_tags):\n",
    "        pr += conf_matrix[tag, tag]\n",
    "        p += sum(conf_matrix[tag, :])\n",
    "        r += sum(conf_matrix[:, tag])\n",
    "    try:\n",
    "        score = 2 * pr / (p + r)\n",
    "    except ZeroDivisionError:\n",
    "        pass\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    def __init__(self, learning_rate=0.001):\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def step(self, grads, params, learning_rate=None):\n",
    "        if learning_rate is None:\n",
    "            learning_rate = self.learning_rate\n",
    "        for param, grad in zip(params, grads):\n",
    "            param -= learning_rate*grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(conf_matrix, labels, title='Confusion matrix', cmap='Oranges'):\n",
    "    norm_cm = conf_matrix / conf_matrix.sum(axis=0)\n",
    "    norm_cm[norm_cm != norm_cm] = .0  # eliminate NaN\n",
    "\n",
    "    fig = Figure(figsize=(7, 7), dpi=120, facecolor='w', edgecolor='k')\n",
    "    ax: Axes = fig.add_subplot(1, 1, 1)\n",
    "    ax.set_title(label=title)\n",
    "\n",
    "    ax.imshow(norm_cm, cmap=cmap)\n",
    "    tick_marks = np.arange(len(labels))\n",
    "\n",
    "    ax.set_xlabel('Actual', fontsize=7)\n",
    "    ax.set_xticks(tick_marks)\n",
    "    ax.set_xticklabels(labels, fontsize=6, rotation=-90, ha='center')\n",
    "    ax.xaxis.set_label_position('bottom')\n",
    "    ax.xaxis.tick_bottom()\n",
    "\n",
    "    ax.set_ylabel('Predicted', fontsize=7)\n",
    "    ax.set_yticks(tick_marks)\n",
    "    ax.set_yticklabels(labels, fontsize=6, va='center')\n",
    "    ax.yaxis.set_label_position('left')\n",
    "    ax.yaxis.tick_left()\n",
    "\n",
    "    for i, j in itertools.product(range(conf_matrix.shape[0]), range(conf_matrix.shape[1])):\n",
    "        ax.text(j, i, format(int(conf_matrix[i, j]), 'd') if conf_matrix[i, j] != 0 else '.',\n",
    "        horizontalalignment='center', verticalalignment='center', fontsize=6, color='black')\n",
    "    fig.set_tight_layout('true')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib.figure import Figure\n",
    "from matplotlib.axes import Axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(conf_matrix, labels, title='Confusion matrix', cmap: str='Oranges'):\n",
    "    norm_cm = conf_matrix / conf_matrix.sum(axis=0)\n",
    "    norm_cm[norm_cm != norm_cm] = .0  # eliminate NaN\n",
    "    \n",
    "    fig: Figure = Figure(figsize=(7, 7))\n",
    "    ax: Axes = fig.add_subplot(1, 1, 1)\n",
    "    ax.set_title(label=title)\n",
    "\n",
    "    ax.matshow(norm_cm, cmap=cmap)\n",
    "    ax.set_xlabel('Actual')\n",
    "    ax.set_ylabel('Predicted')\n",
    "\n",
    "    ax.set_xticklabels([''] + labels, rotation=90)\n",
    "    ax.set_yticklabels([''] + labels)\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    ax.grid(False)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    for i, j in itertools.product(range(conf_matrix.shape[0]), range(conf_matrix.shape[1])):\n",
    "        ax.text(j, i, format(int(conf_matrix[i, j]), 'd') if conf_matrix[i, j] != 0 else '.',\n",
    "                horizontalalignment='center', verticalalignment='center', fontsize=6, color='black')\n",
    "    fig.set_tight_layout('true')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "sheet_delimiter": true,
     "type": "MD"
    }
   },
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "import inspect\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "from typing import List, Optional, Union, Callable\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "num_examples = 1000\n",
    "seq_len = 3\n",
    "max_number = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def get_examples(seq_len, num_examples, max_number):\n",
    "    inputs = np.random.randint(0, max_number, size=(num_examples, seq_len))\n",
    "    targets = np.sort(inputs)\n",
    "    return inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "inputs, targets = get_examples(seq_len, num_examples, max_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs/sorted: ([6, 3, 7], [3, 6, 7])\n",
      "inputs/sorted: ([4, 6, 9], [4, 6, 9])\n",
      "inputs/sorted: ([2, 6, 7], [2, 6, 7])\n",
      "inputs/sorted: ([4, 3, 7], [3, 4, 7])\n",
      "inputs/sorted: ([7, 2, 5], [2, 5, 7])\n",
      "inputs/sorted: ([4, 1, 7], [1, 4, 7])\n",
      "inputs/sorted: ([5, 1, 4], [1, 4, 5])\n",
      "inputs/sorted: ([0, 9, 5], [0, 5, 9])\n",
      "inputs/sorted: ([8, 0, 9], [0, 8, 9])\n",
      "inputs/sorted: ([2, 6, 3], [2, 3, 6])\n"
     ]
    }
   ],
   "source": [
    "for inp, tgt in zip(inputs[:10], targets[:10]):\n",
    "    print(f'inputs/sorted: {list(inp), list(tgt)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def to_string(X, seq_len, max_number):\n",
    "    max_length = int(seq_len * np.ceil(np.log10(max_number + 1)) + seq_len - 1)\n",
    "    Xstr = []\n",
    "    for example in X:\n",
    "        xstr = ','.join([str(n) for n in example])\n",
    "        xstr += ''.join([' ' for _ in range(max_length - len(xstr))])\n",
    "        Xstr.append(xstr)\n",
    "    return Xstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "inputs = to_string(inputs, seq_len, max_number)\n",
    "targets = to_string(targets, seq_len, max_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs[0]: 6,3,7    targets[0]: 3,6,7   \n"
     ]
    }
   ],
   "source": [
    "print(f'inputs[0]: {inputs[0]} targets[0]: {targets[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "vocab = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ',', ' ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def integer_encode(X, vocab):\n",
    "    char_to_int = dict((c, i) for i, c in enumerate(vocab))\n",
    "    Xenc = []\n",
    "    for example in X:\n",
    "        encoded = [char_to_int[char] for char in example]\n",
    "        Xenc.append(encoded)\n",
    "    return Xenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "inputs = integer_encode(inputs, vocab)\n",
    "targets = integer_encode(targets, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs[0]: [6, 10, 3, 10, 7, 11, 11, 11] targets[0]: [3, 10, 6, 10, 7, 11, 11, 11]\n"
     ]
    }
   ],
   "source": [
    "print(f'inputs[0]: {inputs[0]} targets[0]: {targets[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "inputs = np.array(inputs)\n",
    "targets = np.array(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def count_forward_calls(obj):\n",
    "    for prop, value in vars(obj).items():\n",
    "        if isinstance(value, Tensor):\n",
    "            value._forward_calls += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def forks_aware(FunctionClass):\n",
    "    class WrappedClass:\n",
    "        def __init__(self, *args, **kwargs):\n",
    "            self.FunctionClass = FunctionClass(*args, **kwargs)\n",
    "        \n",
    "        def __call__(self):\n",
    "            result = self.FunctionClass()\n",
    "            count_forward_calls(self.FunctionClass)\n",
    "            return result\n",
    "    return WrappedClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "@forks_aware\n",
    "class Function:\n",
    "    def __call__(self) -> \"Tensor\":\n",
    "        pass\n",
    "    \n",
    "    def backward(self, *args, **kwargs):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "class Tensor:\n",
    "    def __init__(self, data: np.ndarray, func: Optional[Function]=None, name: str=None):\n",
    "        self.data: np.ndarray = data\n",
    "        self.grad: np.ndarray = np.zeros(data.shape)\n",
    "        self.func = func\n",
    "        self.__name__ = name\n",
    "        self._forward_calls = 0\n",
    "        self._backward_calls = 0\n",
    "    \n",
    "    def backward(self, grad: Optional[np.ndarray] = None):\n",
    "        self._backward_calls += 1\n",
    "        # print(f'{self.__name__} backward: {self._backward_calls} forward: {self._forward_calls}')\n",
    "        if grad is not None:\n",
    "            assert grad.shape == self.grad.shape\n",
    "            self.grad += grad\n",
    "            if self.func: # and self._forward_calls <= self._backward_calls:\n",
    "                self.func.backward(grad)\n",
    "        else:\n",
    "            if self.func:\n",
    "                self.func.backward()\n",
    "\n",
    "    def zero_grad(self):\n",
    "        self.grad[:] = .0\n",
    "        self._forward_calls = 0\n",
    "        self._backward_calls = 0\n",
    "    \n",
    "    def reshape(self, *args, **kwargs):\n",
    "        return Tensor(self.data.reshape(*args, **kwargs), self.func, self.__name__)\n",
    "    \n",
    "    def transpose(self, *args, **kwargs):\n",
    "        return Tensor(self.data.transpose(*args, **kwargs), self.func, self.__name__)\n",
    "    \n",
    "    @property\n",
    "    def shape(self):\n",
    "        return self.data.shape\n",
    "    \n",
    "    @property\n",
    "    def size(self):\n",
    "        return self.data.size\n",
    "    \n",
    "    def astype(self, dtype: Union[str, np.dtype]):\n",
    "        return self.data.astype(dtype)\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        return str(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "class Module:\n",
    "    def __init__(self):\n",
    "        self.parameters: List[Tensor] = []\n",
    "        self.__name__ = self.__class__.__name__\n",
    "        self.state_dict = {}\n",
    "        self.training = True\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_module_state_dict(module: \"Module\"):\n",
    "        keys = [param.__name__ for param in module.__dict__['parameters']]\n",
    "        values = [param.data.tolist() for param in module.__dict__['parameters']]\n",
    "        return dict(zip(keys, values))\n",
    "     \n",
    "    def update_state_dict(self):\n",
    "        module_state_dicts = []\n",
    "        module_names = []\n",
    "        for key in self.__dict__:\n",
    "            value = self.__dict__[key]\n",
    "            base_class_name = value.__class__.__bases__[0].__name__\n",
    "            # class_name = value.__class__.__name__\n",
    "            if base_class_name == 'Module':\n",
    "                class_has_parameters = hasattr(value, \"parameters\")\n",
    "                if class_has_parameters:\n",
    "                    parameters_not_empty = len(value.parameters) > 0\n",
    "                    if parameters_not_empty:\n",
    "                        module_names.append(key)\n",
    "                        module_state_dict = self.get_module_state_dict(value)\n",
    "                        module_state_dicts.append(module_state_dict)\n",
    "        self.state_dict = dict(zip(module_names, module_state_dicts))\n",
    "\n",
    "    def register_parameter(self, param: Tensor):\n",
    "        self.parameters.append(param)\n",
    "\n",
    "    def register_parameters(self, param_list_or_module: Union[List[Tensor], \"Module\", List[\"Module\"]]):\n",
    "        if isinstance(param_list_or_module, List):\n",
    "            for element in param_list_or_module:\n",
    "                if isinstance(element, Tensor):\n",
    "                    self.register_parameter(element)\n",
    "                elif isinstance(element, Module):\n",
    "                    for param in element.parameters:\n",
    "                        self.register_parameter(param)\n",
    "                else:\n",
    "                    raise TypeError(\"Parameter should be of type Tensor\")\n",
    "        elif isinstance(param_list_or_module, Module):\n",
    "            for param in param_list_or_module.parameters:\n",
    "                self.register_parameter(param)\n",
    "        self.update_state_dict()\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        for param in self.parameters:\n",
    "            param.zero_grad()\n",
    "    \n",
    "    def forward(self, *args, **kwargs):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.forward(*args, **kwargs)\n",
    "    \n",
    "    def size(self):\n",
    "        s = 0\n",
    "        for param in self.parameters:\n",
    "            s += param.data.size\n",
    "        return s\n",
    "    \n",
    "    def update_parameters_from_state_dict(self):\n",
    "        for key in self.__dict__:\n",
    "            if key in self.state_dict:\n",
    "                for param in self.__dict__[key].parameters:\n",
    "                    param.data = np.asarray(self.state_dict[key][param.__name__])\n",
    "\n",
    "    def save(self, filename: str = None):\n",
    "        if filename is None:\n",
    "            filename = time.strftime(\"%Y%m%d-%H%M%S\") + '.json'\n",
    "        self.update_state_dict()\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            json.dump(self.state_dict, f, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    def load(self, filename: str):\n",
    "        with open(filename, 'r') as f:\n",
    "            json_str = f.read()\n",
    "            self.state_dict = json.loads(json_str)\n",
    "        self.update_parameters_from_state_dict()\n",
    "    \n",
    "    def train(self):\n",
    "        for key in self.__dict__:\n",
    "            module = self.__dict__[key]\n",
    "            base_class_name = module.__class__.__bases__[0].__name__\n",
    "            if base_class_name == 'Module':\n",
    "                module.training = True\n",
    "    \n",
    "    def eval(self):\n",
    "        for key in self.__dict__:\n",
    "            module = self.__dict__[key]\n",
    "            base_class_name = module.__class__.__bases__[0].__name__\n",
    "            if base_class_name == 'Module':\n",
    "                module.training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def xavier_(weights):\n",
    "    for weight in weights:\n",
    "        in_dim, out_dim = weight.shape[-2:]\n",
    "        np.copyto(dst=weight.data, src=np.random.randn(*weight.shape) * np.sqrt(2. / (in_dim + out_dim)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def Wandb(in_dim, out_dim):\n",
    "    W = np.random.normal(loc=0, scale=0.1, size=(in_dim, out_dim))\n",
    "    b = np.random.normal(loc=0, scale=0.1, size=(1, out_dim))\n",
    "    return Tensor(W, name='weights'), Tensor(b, name='bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "@forks_aware\n",
    "class Linear(Function):\n",
    "    def __init__(self, x: Tensor, W: Tensor, b: Tensor = None):\n",
    "        super().__init__()\n",
    "        self.x = x\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "    \n",
    "    def __call__(self):\n",
    "        outputs = np.dot(self.x.data, self.W.data) + self.b.data\n",
    "        return Tensor(outputs, func=self, name=\"linear\")\n",
    "\n",
    "    def backward(self, grad: np.ndarray):\n",
    "        # print(f'Linear: x: {self.x.shape} W: {self.W.shape} b: {self.b.shape} grad: {grad.shape}')\n",
    "        dW = np.dot(self.x.data.T, grad)\n",
    "        db = grad.sum(axis=0)\n",
    "        grad = np.dot(grad, self.W.data.T)\n",
    "        self.W.backward(dW.reshape(self.W.shape))\n",
    "        self.b.backward(db.reshape(self.b.shape))\n",
    "        self.x.backward(grad.reshape(self.x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "class LinearLayer(Module):\n",
    "    def __init__(self, in_dim: int, out_dim: int):\n",
    "        super().__init__()\n",
    "        self.W, self.b = Wandb(in_dim, out_dim)\n",
    "        self.register_parameters([self.W, self.b])\n",
    "        self.x = None\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        return Linear(x, self.W, self.b)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "@forks_aware\n",
    "class EmbeddingFunction(Function):\n",
    "    def __init__(self, x: Tensor, E: Tensor):\n",
    "        super().__init__()\n",
    "        self.x = x\n",
    "        self.E = E\n",
    "\n",
    "    def __call__(self):\n",
    "        embeddings = self.E.data[self.x.data.astype('int'), :]\n",
    "        return Tensor(embeddings, func=self, name=\"embedding\")\n",
    "\n",
    "    def backward(self, grad: np.ndarray):\n",
    "        # print(f'Embedding: x: {self.x.shape} E: {self.E.shape} grad: {grad.shape}')\n",
    "        dE = np.zeros_like(self.E.data)\n",
    "        np.add.at(dE, self.x.data, grad)\n",
    "        self.E.backward(dE.reshape(self.E.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "class Embedding(Module):\n",
    "    def __init__(self, vocab_size: int, emb_size: int):\n",
    "        super().__init__()\n",
    "        self.E = Tensor(np.random.normal(loc=0, scale=0.1, size=(vocab_size, emb_size)), name='E')\n",
    "        self.register_parameters([self.E])\n",
    "        self.x = None\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        return EmbeddingFunction(x, self.E)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    s = 1.0 / (1.0 + np.exp(-x))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "@forks_aware\n",
    "class Sigmoid(Function):\n",
    "    def __init__(self, x: Tensor):\n",
    "        super().__init__()\n",
    "        self.x = x\n",
    "\n",
    "    def __call__(self):\n",
    "        self.a = sigmoid(self.x.data)\n",
    "        return Tensor(self.a, func=self, name=\"sigmoid\")\n",
    "\n",
    "    def backward(self, grad: np.ndarray):\n",
    "        # print(f'Sigmoid: x: {self.x.shape} grad: {grad.shape}')\n",
    "        grad = self.a * (1. - self.a) * grad.reshape(self.a.shape)\n",
    "        self.x.backward(grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "class SigmoidFunction(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        return Sigmoid(x)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def tanh(x):\n",
    "    return (np.exp(x) - np.exp(-x)) / (np.exp(x) + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "@forks_aware\n",
    "class Tanh(Function):\n",
    "    def __init__(self, x: Tensor):\n",
    "        super().__init__()\n",
    "        self.x = x\n",
    "\n",
    "    def __call__(self):\n",
    "        self.a = np.tanh(self.x.data)\n",
    "        return Tensor(self.a, func=self, name=\"tanh\")\n",
    "\n",
    "    def backward(self, grad: np.ndarray):\n",
    "        # print(f'Tanh: x: {self.x.shape} grad: {grad.shape}')\n",
    "        grad = (1. - self.a ** 2) * grad.reshape(self.a.shape)\n",
    "        self.x.backward(grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "class TanhFunction(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        return Tanh(x)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "@forks_aware\n",
    "class GetHStack(Function):\n",
    "    def __init__(self, x1: Tensor, x2: Tensor):\n",
    "        super().__init__()\n",
    "        self.x1 = x1\n",
    "        self.x2 = x2\n",
    "\n",
    "    def __call__(self):\n",
    "        stacked = np.hstack((self.x1.data, self.x2.data))\n",
    "        return Tensor(stacked, func=self, name=\"hstack\")\n",
    "\n",
    "    def backward(self, grad: np.ndarray):\n",
    "        # print(f'HStack: x1: {self.x1.shape} x2: {self.x2.shape} grad: {grad.shape}')\n",
    "        assert grad.shape[1] == (self.x1.shape[1] + self.x2.shape[1])\n",
    "        self.x1.backward(grad[:, :self.x1.shape[1]])\n",
    "        self.x2.backward(grad[:, self.x1.shape[1]:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "class HStack(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x1: Tensor, x2: Tensor):\n",
    "        return GetHStack(x1, x2)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "@forks_aware\n",
    "class GetVStack(Function):\n",
    "    def __init__(self, x1: Tensor, x2: Tensor):\n",
    "        super().__init__()\n",
    "        self.x1 = x1\n",
    "        self.x2 = x2\n",
    "\n",
    "    def __call__(self):\n",
    "        stacked = np.vstack((self.x1.data, self.x2.data))\n",
    "        return Tensor(stacked, func=self, name=\"vstack\")\n",
    "\n",
    "    def backward(self, grad: np.ndarray):\n",
    "        # print(f'VStack: x1: {self.x1.shape} x2: {self.x2.shape} grad: {grad.shape}')\n",
    "        grad = grad.reshape((self.x1.shape[0] + self.x2.shape[0], self.x1.shape[1], -1))\n",
    "        self.x1.backward(grad[:self.x1.shape[0], :])\n",
    "        self.x2.backward(grad[self.x1.shape[0]:, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "class VStack(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x1: Tensor, x2: Tensor):\n",
    "        return GetVStack(x1, x2)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "@forks_aware\n",
    "class GetRow(Function):\n",
    "    def __init__(self, x: Tensor, row_idx: int):\n",
    "        super().__init__()\n",
    "        self.x = x\n",
    "        self.row_idx = row_idx\n",
    "\n",
    "    def __call__(self):\n",
    "        row = self.x.data[self.row_idx]\n",
    "        return Tensor(row, func=self, name=\"row_\"+str(self.row_idx))\n",
    "\n",
    "    def backward(self, grad: np.ndarray):\n",
    "        # print(f'Row: x: {self.x.shape} grad: {grad.shape}')\n",
    "        dx = np.zeros_like(self.x.data)\n",
    "        dx[self.row_idx] = 1\n",
    "        dx *= grad\n",
    "        self.x.backward(dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "class Row(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x: Tensor, idx: int):\n",
    "        return GetRow(x, idx)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def softmax_numpy(x):\n",
    "    a = np.amax(x, axis=1)[:, np.newaxis]\n",
    "    ex = np.exp(x - a)\n",
    "    ex_sum = np.sum(ex, axis=1)[:, np.newaxis]\n",
    "    out = ex / ex_sum\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def softmax(x: Tensor):\n",
    "    out = softmax_numpy(x.data)\n",
    "    return Tensor(out, func=x.func, name=\"softmax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "@forks_aware\n",
    "class SoftMax(Function):\n",
    "    def __init__(self, x: Tensor):\n",
    "        super().__init__()\n",
    "        self.x = x\n",
    "\n",
    "    def __call__(self):\n",
    "        self.a = softmax_numpy(self.x.data)\n",
    "        return Tensor(self.a, func=self, name=\"softmax\")\n",
    "\n",
    "    def backward(self, grad: np.ndarray):\n",
    "        # print(f'Softmax: x: {self.x.shape} grad: {grad.shape}')\n",
    "        a = self.a.reshape(-1, 1)\n",
    "        grad = np.diagflat(a) - np.dot(a, a.T)\n",
    "        self.x.backward(grad.reshape(self.x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "class SoftMaxFunction(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        return SoftMax(x)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def one_hot_encoder(inputs: Tensor, vocab_size: int):\n",
    "    seq_len, batch_size = inputs.shape\n",
    "    encoded = np.zeros((seq_len * batch_size, vocab_size))\n",
    "    encoded[np.arange(seq_len * batch_size), inputs.data.ravel().astype(int)] = 1\n",
    "    return Tensor(encoded.reshape(seq_len, batch_size, vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "@forks_aware\n",
    "class NLL(Function):\n",
    "    def __init__(self, y_hat: Tensor, y: Tensor, eps: float = 1e-15):\n",
    "        super().__init__()\n",
    "        self.seq_len, self.batch_size = y.shape[0], y.shape[-1]\n",
    "        num_classes = y_hat.shape[-1]\n",
    "        self.y_hat = softmax(y_hat)\n",
    "        self.y = one_hot_encoder(y, num_classes)\n",
    "        self.y = self.y.reshape(-1, num_classes)\n",
    "        self.eps = eps\n",
    "\n",
    "    def __call__(self):\n",
    "        logs = np.log(self.y_hat.data + self.eps)\n",
    "        loss = np.multiply(-self.y.data, logs).sum(axis=1).mean()\n",
    "        return Tensor(loss, func=self, name=\"nll\")\n",
    "    \n",
    "    def backward(self):\n",
    "        grad = self.y_hat.data - self.y.data\n",
    "        self.y_hat.backward(grad / float(self.batch_size)/ float(self.seq_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "class CrossEntropyLoss(Module):\n",
    "    def __init__(self, eps=1e-15):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        return NLL(output, target, self.eps)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "class RNNCell(Module):\n",
    "    def __init__(self, state_size: int, hidden_size: int):\n",
    "        super().__init__()\n",
    "        self.linear = LinearLayer(state_size, hidden_size)\n",
    "        self.tanh = TanhFunction()\n",
    "        self.hstack = HStack()\n",
    "        self.register_parameters([self.linear])\n",
    "\n",
    "    def forward(self, x: Tensor, h_t_1: Optional[Tensor] = None):\n",
    "        X = self.hstack(x, h_t_1)\n",
    "        z = self.linear(X)\n",
    "        h_t = self.tanh(z)\n",
    "        return h_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "class RNN(Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.state_size = input_size + hidden_size\n",
    "        self.rnn = RNNCell(self.state_size, hidden_size)\n",
    "        self.row = Row()\n",
    "        self.vstack = VStack()\n",
    "        self.register_parameters([self.rnn])\n",
    "\n",
    "    def forward(self, x: Tensor, h_t_1: Optional[Tensor] = None):\n",
    "        seq_len, batch_size, input_size = x.shape\n",
    "        # print(f'seq_len: {seq_len} batch_size: {batch_size} input_size: {input_size}')\n",
    "        h = Tensor(np.zeros((0, batch_size, self.hidden_size)), name=\"h\")\n",
    "        if h_t_1 is None:\n",
    "            h_t_1 = Tensor(np.zeros((batch_size, self.hidden_size)), name=\"h_t_1\")\n",
    "        for idx in range(seq_len):\n",
    "            h_t_1 = self.rnn.forward(self.row(x, idx), h_t_1)\n",
    "            h = self.vstack(h, h_t_1.reshape((1, batch_size, self.hidden_size)))\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "class RecurrentNetwork(Module):\n",
    "    def __init__(self, vocab_size: int, emb_size: int, hidden_size: int):\n",
    "        super().__init__()\n",
    "        self.emb_size = emb_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = Embedding(vocab_size, emb_size)\n",
    "        self.rnn = RNN(emb_size, hidden_size)\n",
    "        self.linear = LinearLayer(hidden_size, vocab_size)\n",
    "        xavier_(self.linear.parameters)\n",
    "        self.register_parameters([self.embedding, self.rnn, self.linear])\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        emb = self.embedding(x)\n",
    "        rnn_out = self.rnn(emb)\n",
    "        linear_out = self.linear(rnn_out.reshape(-1, self.hidden_size))\n",
    "        return linear_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "    def __init__(self, params: List[Tensor], lr: float = 0.001):\n",
    "        self.params = params\n",
    "        self.lr = lr\n",
    "\n",
    "    def step(self, *args, **kwargs):\n",
    "        raise NotImplemented\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        for param in self.params:\n",
    "            param.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "class SGD(Optimizer):\n",
    "    def __init__(self, params: List[Tensor], lr: float = 0.001):\n",
    "        super().__init__(params, lr)\n",
    "\n",
    "    def step(self):\n",
    "        for param in self.params:\n",
    "            param.data -= self.lr * param.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "class Scheduler:\n",
    "    def __init__(self, optimizer: Optimizer, last_epoch: int = -1):\n",
    "        self.optimizer = optimizer\n",
    "        self.base_lr = optimizer.lr\n",
    "        self.last_epoch = last_epoch\n",
    "    \n",
    "    def step(self):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "class ConstantLR(Scheduler):\n",
    "    def __init__(self, optimizer: Optimizer):\n",
    "        super().__init__(optimizer)\n",
    "        self.lr = optimizer.lr\n",
    "    \n",
    "    def step(self):\n",
    "        self.last_epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "class CosineAnnealingLR(Scheduler):\n",
    "    def __init__(self, optimizer: Optimizer, T_max: int, eta_min: float = 0, anneal_epochs: int = None, last_epoch: int = -1):\n",
    "        super().__init__(optimizer)\n",
    "        self.T_max = T_max\n",
    "        self.eta_min = eta_min\n",
    "        self.lr = optimizer.lr\n",
    "        self.last_epoch = last_epoch\n",
    "        self.start_epoch = last_epoch\n",
    "        self.anneal_epochs = anneal_epochs\n",
    "    \n",
    "    @staticmethod\n",
    "    def _cosine_anneal(t):\n",
    "        return (1 + np.cos(np.pi * t)) / 2\n",
    "\n",
    "    def get_lr(self):\n",
    "        if self.anneal_epochs is not None:\n",
    "            passed_epochs = self.last_epoch - self.start_epoch\n",
    "            if passed_epochs > self.anneal_epochs:\n",
    "                return self.lr\n",
    "        t = self.last_epoch / self.T_max\n",
    "        return self.eta_min + (self.base_lr - self.eta_min) * self._cosine_anneal(t)\n",
    "    \n",
    "    def step(self):\n",
    "        self.lr = self.get_lr()\n",
    "        self.optimizer.lr = self.lr\n",
    "        self.last_epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, data, target, batch_size=20):\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def next(self):\n",
    "        m, _ = self.data.shape\n",
    "        rand_index = np.random.choice(m, size=m, replace=False)\n",
    "        X, y = self.data[rand_index], self.target[rand_index]\n",
    "        pos = 0\n",
    "        while pos < m:\n",
    "            X_batch, y_batch = X[pos:pos+self.batch_size], y[pos:pos+self.batch_size]\n",
    "            yield Tensor(X_batch, name=\"x\"), Tensor(y_batch, name=\"y\")\n",
    "            pos += self.batch_size\n",
    "\n",
    "    def __call__(self):\n",
    "        return self.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def eval_accuracy(model, val, y_val):\n",
    "    model.eval()\n",
    "    output = model(Tensor(val))\n",
    "    y_hat = np.argmax(output.data, axis=1)\n",
    "    model.train()\n",
    "    return accuracy_score(y_val.ravel(), y_hat.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "vocab_size = len(vocab)\n",
    "emb_size = 20\n",
    "hidden_size = 32\n",
    "batch_size = 100\n",
    "dataloader = DataLoader(inputs, targets, batch_size=batch_size)\n",
    "model = RecurrentNetwork(vocab_size, emb_size, hidden_size)\n",
    "loss_function = CrossEntropyLoss()\n",
    "optimizer = SGD(model.parameters, lr=1.0)\n",
    "# optimizer = Adam(model.parameters, alpha=0.1, beta1=0.9, beta2=0.999, eps=1e-8, weight_decay=0.01)\n",
    "scheduler = ConstantLR(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2332"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch: [50/50], loss: 3.3334639835805806, acc: 0.88375"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "accuracies = []\n",
    "lrs = []\n",
    "for epoch in range(num_epochs):\n",
    "    loss_sum = 0\n",
    "    for data in dataloader():\n",
    "        optimizer.zero_grad()\n",
    "        inputs, targets = data\n",
    "        inputs = inputs.transpose(1, 0)\n",
    "        targets = targets.transpose(1, 0)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_sum += loss.data\n",
    "    acc = eval_accuracy(model, inputs.data, targets.data)\n",
    "    print(f'\\r epoch: [{epoch+1}/{num_epochs}], loss: {loss_sum}, acc: {acc}', end='')\n",
    "    losses.append(loss_sum)\n",
    "    accuracies.append(acc)\n",
    "    lrs.append(scheduler.lr)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2cAAAE/CAYAAADCCbvWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAABbEklEQVR4nO3dd3Sc1bX38e+eGXXJ6rYsS3Lvxg1j03sxBGzSgUAIIZS8IQkpNyH3JqTc9EpuICGQ0EMLSbBJqAndYMA2li33bhUXybZ615z3jxkZ2ZZklZFGI/0+a2lJ87TZelwebe1z9jHnHCIiIiIiIhJennAHICIiIiIiIkrOREREREREBgQlZyIiIiIiIgOAkjMREREREZEBQMmZiIiIiIjIAKDkTEREREREZABQciYiIiIiIjIAKDkTaYeZ7TSz88Mdh4iISLiY2atmdsjMYsIdi8hQoeRMRERERI5gZmOAMwAHLOrH9/X113uJDERKzkS6yMxizOwOMysJftzR+ttEM8sws3+aWbmZHTSzN8zME9z3TTMrNrMqM9tkZucFt3vM7DYz22ZmB8zsSTNLC+6LNbNHgtvLzew9MxsRvu9eRESGmE8Dy4EHgGtbN5pZrpn93cxKg8+oO9vsu8HMNgSfd+vNbG5wuzOzCW2Oe8DMfhj8+mwzKwo+K/cC95tZavCZWhqs3P3TzHLanJ9mZvcHn8WHzOzp4PYCM7uszXFRZlZmZnP66iaJhJqSM5Gu+x/gZGA2MAuYD3w7uO9rQBGQCYwA/htwZjYZuAU4yTmXBFwE7Aye80XgcuAsIBs4BNwV3HctkAzkAunAzUBdX31jIiIiR/k08Jfgx0VmNsLMvMA/gV3AGGAU8DiAmX0c+F7wvGEEqm0HuvheWUAaMBq4kcDPp/cHX+cReP7d2eb4h4F4YDowHPhNcPtDwNVtjrsE2OOce7+LcYiEnUrHIl33KeCLzrn9AGb2feCPwHeAJmAkMNo5txV4I3hMCxADTDOzUufczjbXuxm4xTlXFDz2e8BuM7smeL10YIJzbg2wsu+/PRERETCz0wkkRk8658rMbBtwFYFKWjbwX8655uDhbwY/fw74uXPuveDrrd14Sz/wXedcQ/B1HfC3NvH8CHgl+PVI4GIg3Tl3KHjIa8HPjwDfMbNhzrlK4BoCiZxIxFDlTKTrsgn8trDVruA2gF8QeBC9aGbbzew2gGCidiuB3ybuN7PHzaz1nNHAP4LDFsuBDUALgcrbw8ALwOPBYRs/N7OovvzmREREgq4FXnTOlQVfPxrclgvsapOYtZULbOvh+5U65+pbX5hZvJn90cx2mVkl8DqQEqzc5QIH2yRmhznnSoBlwEfNLIVAEveXHsYkEhZKzkS6roRAQtUqL7gN51yVc+5rzrlxBIZyfLV1bplz7lHnXOtvIR3ws+D5hcDFzrmUNh+xzrli51yTc+77zrlpwKnApQSGioiIiPQZM4sDPgGcZWZ7g/PAvkJgOP8+IK+Dph2FwPgOLltLYBhiq6yj9rujXn8NmAwscM4NA85sDS/4PmnB5Ks9DxIY2vhx4G3nXHEHx4kMSErORDoWFWzMEWtmscBjwLfNLNPMMoDbCQyhwMwuNbMJZmZABYEKmN/MJpvZucHGIfUEhmr4g9e/G/iRmY0OXiPTzBYHvz7HzE4I/pawksAwRz8iIiJ963ICz7BpBOZYzwamEhiufzmwB/ipmSUEn4+nBc/7E/B1MzvRAia0Pt+A1cBVZuY1s4UE5lp3JonA87I82Cjru607nHN7gOeA3wcbh0SZ2Zltzn0amAt8mcAcNJGIouRMpGPPEng4tH7EAiuANcBaYBXww+CxE4F/A9XA28DvnXOvEJhv9lOgDNhLYOLyt4Ln/BZYSmAoZBWBsfwLgvuygKcIJGYbCIyn17h5ERHpa9cC9zvndjvn9rZ+EGjIcSVwGTAB2E2gEdYnAZxzfwV+RGAIZBWBJCkteM0vB88rJzB/++njxHAHEEfg2bkceP6o/a1zszcC+wlMHyAYR+t8tbHA37v+bYsMDObc0ZVkEREREZHIZGa3A5Occ1cf92CRAUbdGkVERERkUAgOg7yeQHVNJOJoWKOIiIiIRDwzu4FAw5DnnHOvhzsekZ7QsEYREREREZEBQJUzERERERGRAUDJmYiIiIiIyADQrw1BMjIy3JgxY/rzLUVEJAxWrlxZ5pzLDHcckULPRxGRoaOzZ2S/JmdjxoxhxYoV/fmWIiISBma2K9wxRBI9H0VEho7OnpEa1igiIiIiIjIAKDkTEREREREZAJSciYiIiIiIDABKzkRERERERAYAJWciIiIiIiIDgJIzERERERGRAUDJmYiIiIiIyACg5ExERERERGQAUHImIiIiIiIyAERUcramqJxH39kd7jBERERERIac4vI68gvLwx3GoBZRydm/N+znv/+xFr/fhTsUEREREZEhY+v+ahbf+SYf/cNbvLvjYLjDGbQiKjlLiPYCUNfUEuZIRERERESGhh1lNVx173LAyEmN4/OPrKS4vC7cYQ1KEZWcxcf4AKhpbA5zJCIiIiIiA9db28ooKK7o9XV2H6jlqnuX0+J3PHrDAv507Uk0Nvu58aEV1DWqYBJqEZWctVbOahv0F0FEREREpD3/eL+IT/3pHb742Ps41/PpQEWHarny3uXUNbXwyOcWMGlEEhOGJ/J/V85h/Z5K/uup/C5fv7qhmcr6pnY/Gpv9PY5xsPGFO4DuSFDlTERERESkQ8/kl/C1J/PJSIxhR1kNq3Yf4sTRad2+zp6KOq669x2q6pt49IaTmTpy2OF950wZzjcumsLPnt/ItOxh/L+zJ3R4ne2l1dy+ZB1vbi3r8JjU+Cgev/EUJmcldTvOwSaykrPoYHKmypmIiIjIkLCttJpn1+zhC+dMwOOxcIczoD1fsIdbn1jNvNFp3PWpuZz1i1d4amVRt5OzfZX1XHXvOxyqaeSRzy1gxqjkY465+axxbNhTyS9e2MTkEUmcN3XEEfvrm1r4/Stbufu17cREefjSuRMYFhfV7vv98fXt3PDQCpZ84TRSE6K7FWt3Happ5IG3dnLtqWNI6+P36omISs7iYwLDGlU5ExERERn86ptauPnhlWzZX83J49M5aUz3K0BDxb/X7+OWR99nVk4y9113EokxPi6eMZJ/5u/h9kunExecHnQ8pVUNXHXvcvZX1vPQ9fOZlZvS7nFmxs8+OpPtZdV8+fHVPP2FU5kwPFD5enXTfr67dB27DtRy+exs/vtDUxmeFNvhe87JS+XKe5Zzy2OrePC6+fi8fTPzqqK2iav//A7rSirZdaCGO66Y0yfv0xsRNucskEtqzpmIiIjI4Pfz5zexZX81UV5j6eqScIczYL2yaT//7y+rmJY9jAc+O5/E4FSgj52YQ1VDMy+u39vla33tr/mUlNdz/3Xzj1txi4v2cs8184iN8nDDQyvZvK+KL/xlFZ+5/z28Zvzlcwu444o5nSZmACeOTuWHH57Bsq0H+PGzG7sca3dU1jfx6fveYcu+as6fOoKnV5fw1raOh1qGS0QlZ/HRqpyJiIiIDAVvbinjvmU7uPaU0Vw4PYtn1+6hqWXwNY5o8Tu+/8w6lm8/0KPz39xSxk0Pr2TiiEQe/uwChsV+MHRwwdg0clLjeGplUZeu9f7uQ7y+uZSvXDCR+WO7VqXMTonjD1efSNGhWi78zev8e8M+vnbBJJ679QxOm5DR5e/jE/Nyue60Mdy3bAd/XVHY5fO6orqhmc/c9y7r91Tyh6vncudVc8hLi+c7TxcMuGYkx03OzOw+M9tvZgVHbf+imW00s3Vm9vO+C/EDrQ1BahuUnImIiIgMVuW1jXz9r/mMz0zgtounsmhWNgdqGlnWSVOJSHX3a9u4f9lO7npla7fPfXvbAT730HuMy0jgkesXkBx/5Jwuj8f42Ik5vLm1rEvrkv3u5a2kxkfxqQWjuxXHSWPS+NUnZrN4djYvfuVMvnjeRGJ8XRtG2db/XDKV0yak8z//KGDV7kPdPr89tY3NfPb+98gvquB3V87lvKkjiI3y8v3F09lWWsO9b2zv8rWeL9hDfR+vt9yVytkDwMK2G8zsHGAxMMs5Nx34ZehDO9YHlTMNaxQREREZrL6zZB1l1Q3c8ck5xEV7OXtyJkmxPpbmD66hjQXFFfzmpc3ER3t5e9sBymsbu3xui99x6xPvMyoljkc+t6DDRhofnZuDc/CPVZ1XzwqKK3h5434+d8a4wwWR7lg0K5vfXjGH0ekJ3T63lc/r4c4r55KVHMtND69kb0V9j68FUNfYwvUPrGDFroP89orZLJyRdXjfOZOHs3B6Fr97eQuFB2uPe60Hlu3g5kdWcd+yHb2K6XiOm5w5514HDh61+fPAT51zDcFj9vdBbMeI8XnweYwaVc5EREREBqUlq4t5Jr+EW8+fyAk5gS6BMT4vF8/I4sV1+7pcudi8r4rPPbii1z/g95X6phZufWI16YnR/OHqE2n2O15av6/L5y/ffoB9lQ189YLJZCTGdHhcblo8J49L46mVRZ2uSfZ//9nCsFgfnz6le1WzUEtNiObeT8+jtqGZmx5eccSfd2V9E29tK+Pu17bxhb+s4rLfvclXn1jN/ct2sHLXoSOOrW9q4caHV7B8xwF+/YnZXDoz+5j3uv2yaXjM+P4z6zuN6ZHlu/jeM+u5aPoIbjhjXOi+2Xb0tFvjJOAMM/sRUA983Tn3XujCap+ZER/tpVaVMxEREZFBp7i8jm8/XcCJo1O5+azxR+xbNGsUT64o4pWN+7n4hJHHvdbPn9/IvzfsJybKw11Xze2rkHvsp89tZOv+ah6+fj6nT8hgVEoczxfs5ePzcrt0/tLVJSREezlv6vDjHvuxE3P5+l/zWbnrEPPa6Xi5YU8lL67fx5fPm0hSbPvt7vvT5Kwkfv3J2dz08EpuenglqfFRrCmuYHtpzeFjctPiyEuL542tZfz9/WIAvB5j0ogkZo5KpvBQLW9vP8DPPzqTy+eMavd9slPi+PJ5E/nJcxt5af0+Lpg24phjnnhvN99+uoDzpgznd1fOJaqPOkm26mly5gPSgJOBk4AnzWycaycdN7MbgRsB8vLyehrnYQkxPlXORERERAYZv9/x9Sfz8fsdv/7ErGPaqZ8yPp2MxBiWrC45bnK2rqSCf2/Yz7iMBP61Zg+fnFfKmZMy+zL8bnljSykPvLWTz5w6hjMmBuJaOCOLh9/eRVV903ETpIbmFp4t2MNF07OIjTr+3K6LZ2Rx+5ICnlpZ1G5yducrW0mM8fHZ08b27BvqAxdNz+JrF0ziVy9tJmtYLCfkJPOROaM4ISeFmaOSjxjGubeinjVF5awtriC/qIIX1++lqr6ZH3/4hOMmu589fSx/W1XE95au47QJ6cRHf5Ae/W1lEbf9fS1nTcrk91fPJdrX970Ue5qcFQF/DyZj75qZH8gASo8+0Dl3D3APwLx58zqupXaRKmciIiIig899y3bw9vYD/OyjJ7Q7b8nrMS6dOZJH391NZX3TEV0Jj3bny1tJivHx5M2n8PG73+b2JQU8f+uZXUpk+tqRzU6mHN5+8Yws/vzmDl7euJ/Fs9uv9LR6bVMpVfXNXDb72KF67UmI8fGhE0byzzV7+O5lR655tnV/Fc+u3cPnzxp/TEORcPvieRO59rQxnf5ZA2Qlx5KVnMWF0wNzypxzNDT7u/TnHeX18MPLT+ATf3ybO1/eyjcWBv5Mlqwu5r+eyufU8en88ZoTe9TgpCd6mv49DZwDYGaTgGigX9rnJMT41EpfREREZBDZtLeKnz+/iQumjeATnVQ6Fs3OprHZz4vrOp6btWlvFc8V7OW608aQkRjD/y6ewc4Dtdz92ra+CL1bnHP8z9MFHKhu5LdXzDkieZibl8rwpBieW3v8NcmW5peQGh/F6d1oVf+xE3Oobmjm+XV7jth+1yvbiPV5uf70gVM1a+t4iVl7zKxbifj8sWl8dG4O976x/XCy+tUn8zlpTBp/+vRJ/ZrUd6WV/mPA28BkMysys+uB+4Bxwfb6jwPXtjeksS/ER3u1CLWIiIjIIOGc43tL15EY6+MnHzkBM+vw2Dm5KeSmxbFkdXGHx9z5ylYSor18NphsnD4xg8tmZfP7V7exs6ymw/P6w9Ori/nXmj185YJJzBiVfMQ+j8dYOCOLVzfvp7aTQkRNQzP/3rCPD80c2a35TyeNSSMvLf6INc92ltWwZHUxV5+cR3onTUWGgv++ZArx0T5uenglX3rsfebkpnDfZ046osrYH7rSrfFK59xI51yUcy7HOfdn51yjc+5q59wM59xc59zL/REsQKIqZyIiIiKDxqubS3l7+wG+dO6ETrsOQqAismhWNm9tO0BZdcMx+7eVVvPPNSVcc8oYUuI/mJP07Q9NJdrr4fal6zrtWNiXisvruP3pde02O2m1cEYW9U1+Xt10zEyhw15av4/6Jj+LZnU+9PFoHo/x0bk5vLXtAEWHAq3jf//qVqK8Hm44s287EEaC9MQYvrFwMttKa5gxKpn7rzupR0sK9Fbfz2oLsfhoNQQRERERGQxa/I6fPbeR0enxXNXFhY8XzRpFi9/x7No9x+y765WtxPg8fO6MI4fojRgWy9cunMTrm0t5ruD4wwZDbePeSr746Cr8zvGbT8zG62m/Ojh/TBrpCdGdxrg0v4SRybHMG53a7Tg+MndUcM2zYgoP1vL3VcVcOT+P4Umx3b7WYHTlSXncffWJPHT9/LB1rYy45CwhxqtFqEVEREQGgaffL2bj3iq+fuHkLnfCm5yVxOQRSSxZfeSC1LsP1LJkdQmfWjC63QrcNSePZtrIYfzgmfVU98Mv+uubWvjH+0V89A9vsfCONygoqeTHHzmBvPT4Ds/xeT1cOH0EL29ofz23QzWNvL65lEWzsvF0kOB1JjctnlPHp/PUqiL+8No2PGbcdJaqZq1ah5b2ZJ5byGII2zv3UHy0j1pVzkREREQiWn1TC79+aTMzc5L5UBfWLWtr0exsVu46dHh4HgSG6Hk9xk0dDNHzeT388MMz2FdVzx0vbe5V7J3ZdaCGnzy7gVN/+jJfeSKfA9UN/M8lU3nnW+cdtwsjwMIZI6lpbOGNLcf22nu2YA/Nfsdls7rWpbE9Hzsxh10Hanns3d18bF4OI5PjenwtCb2IS84Sor3UNrXg94dnvLCIiIjIUPbc2j386Y3tvb7OQ2/vpLi8jtsuntLtKtCiYHLyTH5gaGNxeR1/W1XEFSflMnxYx0P05ualcsVJedz/1k427KnsefDt2LKviuvuf5ezfvEqf3pzB/PHpPHI9Qt4+Wtnc8OZ445Yl6szp45PJzkuiucKjh22uXR1CeMyE5iePazHcS6ckUVCtBevGZ/vYO6bhE//z3LrpfgYH85BfXPLEYvEiYiIiEjf+9ObO1i1+xDnTBnO+MzEHl2joraJu17ZxtmTMzl1fNfbwbfKTYtnTl4KS1YX8/mzx3P3q4E2+R012mjrGxdN5oV1e/n20wX89aZTejQ8sK26xhb+7+Ut3Pv6dhJifNx6/kSuOCmPrOSezeOK8no4f+oIXly/l8Zm/+Hhnnsq6nh350FuPW9Spx0tjyc+2sfXL5pMY7Of3LSOh1hKeERe5SzYNaVG7fRFRERE+pVzjs37qnAu0Hyjp37/6lYq65v45sIpxz+4A4tmZbNxbxVvbinjiRWFfOzEHLJTjj9ELzUhmtsunsLKXYf4Qy/XPvvPhn2c/+vX+MOr27h8zihe/tpZ3Hr+pB4nZq0uOSGLqvpm3tr2wdDGf+bvwbnAkM7euu60sdykqtmAFHnJWXCtAXVsFBEREelf+yobqKpvJiMxhiWrS9h9oPb4Jx2luLyO+9/ayUfm5DB1ZM+H531o5kg8Bl94dBUtfsfnz5rQ5XM/fmIOi2dn88sXN/Hv9R0vaN2R4vI6bnxoBdc/uIKEGC9P3nQKv/z4rJCtFXb6xAwSY3xHLEi9NL+EE0YlMzYjISTvIQNTxCVnrUMZtdaZiIiISP/avK8KgO9cOhWvx/j9q92vnv36xUAzjq9eOKlXsQxPiuXU8RlU1DVx+exRnXZBPJqZ8bOPzmR69jBufWI1W4Lf1/H4/Y57Xt/G+b96jde3lPLNhVP45xfPYP7YtJ5+G+2K8Xk5d8pwXly/l+YWPzvKalhbXMHiEFTNZGCLuOQsISZQOatVO30RERGRftWanJ02IYMrTsrlb6uKKC6v6/L5G/ZU8vf3i/jMqWMY1YUhiMfzyZNyiY3y8IVzuj9ELzbKyz3XzCM2ysMND62gorap0+Or6pu48eEV/PjZjZw2IZ1/f/UsPn/2+C4vAdBdl5yQxaHaJt7dcZClq0swg0tnKjkb7CIuOTtcOdOwRhEREQmDfZX1XPib10Le7S8SbNlXTVpCNBmJMYebb7Q24+iKnz2/kaQYH//v7NDMd7psVjbvf+dCxvWwMUl2Shx3X30ixeV13PLYKppb/O0et7Osho/8/i1e2VTK/y6ezr2fnkdOat820zhr0nDiorw8W7CHJfnFzB+T1uu5bDLwRVxypsqZiIiIhNPy7QfYvK+aJ1cUhvS6z63dw/6q+pBeM9Q2769i4vBAIpSdEsfHTszhifcK2Vtx/LiXbS3j1U2lfOGcCaTEd62tfFfEBfsR9NS8MWn8YPEM3thSxs+e33jM/je3lLH4rmWUVjfw8PXzueaUMb3qlthVcdFezpmSyVMri9heWtOlNdIk8kVecqbKmYiIiIRRQXEFAC8U7MW50Ky7ur+yns//ZRX3vt779cP6inOOLfuqmZyVdHjb58+aQItz/PH1zqtnG/dWcsujq8hLi+faU8f0caTdd+X8PD59ymjufWMHf19VBAS+3/uX7eDa+98la1gsS79weo/a/vfGwhkjqW/y4/MYF8/I6tf3lvCIvOQs2EpflTMREREJh4LiSsygpKKe/KKKkFxzdWE5AKt2l4fken2hpKKe6oZmJo74IDnLS4/n8tmjePSd3ZRWNbR73pZ9VXzq3neI8Xl5+Pr5xEb1rtLVV75z6TROHpfGbX9fy3s7D/LNv63h+8+s57wpw/nb/zu1Ww1HQuXcKcOJ9nk4c1JmlxexlsgWcclZfLB0Xa3KmYiIiPQz5xwFJRV86ISR+DzGc2v3hOS6+UXlAKwtrqCxuf15T+HW2gxk0vAj53d94ZzxNLX4+dMbx1b9tpdWc9Wf3sHjMR69YQGj0wduG/gor4fff+pEhifF8PG73+bJFUV86dwJ3H31iSQGiwP9LTHGx4PXzecHi6eH5f2l/0Vcchbj8+D1GLVqpS8iIiL9rPBgHVX1zZw2IYPTJmTwXIiGNq4uLMcMGpv9rCsJTTUu1FrbzU9qUzkDGJeZyKUzs3l4+S4O1jQe3r7rQA1X3fsOfr/jsRsW9LhpR39KS4jm3k/PY1ZOMnddNZevXjgZj6fv55d15pTx6X3efEQGjohLzsyM+GgvNQ0a1igiIiL9qyCYOM3ITubiGVnsPljLupLedW30+x1rCis4b8pwYOAObdy8r5qMxJh2h9fdcu4EahtbuO/NHQAUHqzlynuW09Dcwl9uWMCE4UnHnDNQTR05jCW3nM6HZo4MdygyBEVccgaBpiCqnImIiEh/KyiuwOcxJmUlcuH0LLwe4/mCvb265vayGqoamrlwehbZybG8v/tQiKINrS37qpg0ov3q16QRSVw8I4sH39rJxr2VXHnvcmoaW3jkcwuYkjWsnyMViVwRmZzFx3ipUUMQERER6WcFJZVMGpFEjM9LWkI0C8am8WzBnl4NbWxtBjInN4U5o1N5fwBWzvx+x5b91ccMaWzrlnMnUNXQzKLfLaOitomHr5/P9OzkfoxSJPJFZHKWGOOjVg1BREREpB8551hXXMGMUR9Ugi6ekcX20hq27K/u8XXzC8tJjPExLjORuXmpFJfXsa9yYK13VlxeR21jCxM7qJwBTM9OZuH0LKJ9Hh68fj4zc1L6L0CRQSIikzPNORMREZH+treyngM1jcwY9UE16KLpWZjBc2t7PrRxdWE5M3OS8XqMuXkpAKza1fuhjc45bl9SwC9f2ERzS+86QG7ZH2gGMrmTyhnAHVfM5vVvnMPcvNRevZ/IUBWRyVlCtI8azTkTERGRflRQHGj80Xao3vBhscwbncpzBT1rqV/f1MKGPZXMyk05fO1on4dVIZh39uzavTz09i7ufGUr1z3wHhW1TT2+1qa9gcrgxOMkZ7FRgeGeItIzEZmcxcf4tAi1iIiI9KuC4go8BlNHHpmgLJwxko17q9hRVtPta67fU0mz3zErOAQw2udhRvawXndsrG5o5gf/XMe0kcP4yUdOYPn2A1z++2VsDVbAumvLvipGDIshOS6qV3GJSOciMjlLiPZSozlnIiIi0o/WlVQwPjOR+OgjFyReOCMLoEfVs9XBJGxOcDgjwNy81F4vRv2blzazv6qBH314BlfOz+OxG06mqr6JD9/1Fq9s3N/t623eX9VpMxARCY2ITM7io1U5ExGRvmVmC81sk5ltNbPb2tmfZ2avmNn7ZrbGzC4Jbh9jZnVmtjr4cXf/Ry99oaC48oj5Zq1GpcQxKzelR/PO8ovKyRoWy4hhsYe3zR2dSmOzn/V7erZ+2vqSSh54aydXnJTHnODcr3lj0lhyy+nkpcfz2Qff4+7XtnW5w6Tf79i6v5qJEbRWmUikisjkLDHGS01jc6/a1oqIiHTEzLzAXcDFwDTgSjObdtRh3waedM7NAa4Aft9m3zbn3Ozgx839ErT0qdKqBvZW1jM9u/01uy6ZkcXa4goKD9Z267r5heXMDs43a9XaTKMnTUH8fsd3lhSQHBfFNxdOPmLfqJQ4nrr5VC45YSQ/fW4jX3liNfVNx/9ld+GhWuqb/B2ucSYioRORyVl8jA/noL6pd52HREREOjAf2Oqc2+6cawQeBxYfdYwDWn9STwZK+jE+6WfrSioA2q2cAVw8YyRAtxakPlTTyM4DtYebgbTKSo4lOzm2R01BnlpZxMpdh/jWxVNIiT+2MUdctJc7r5zDf100madXl/DNv6057jU37+taMxAR6b2ITM4Sor1AYLKriIhIHxgFFLZ5XRTc1tb3gKvNrAh4Fvhim31jg8MdXzOzM/o0UukX60oCQwyndVA5y0uPZ9rIYd2ad5ZfVA7ArNxjE76eLEZ9qKaRnzy3gZPGpPLRuTkdHmdmfOGcCXzm1DE8t3YvFXWdd3HcvC/QRESVM5G+F5HJWetE3Fq10xcRkfC5EnjAOZcDXAI8bGYeYA+QFxzu+FXgUTM75id6M7vRzFaY2YrS0tJ+DVy6r6C4gjHp8QyL7bhb4SUnZLFqdzl7K7q2gPTqwnLMaHex5jm5Kd1ejPpnz2+ksr6ZH15+Ah6PHff4y+eMorHFzwvrOq/2bdlXRXZyLEmdfO8iEhrHTc7M7D4z229mBe3s+5qZOTPL6Jvw2pcQE6icaSFqERHpI8VAbpvXOcFtbV0PPAngnHsbiAUynHMNzrkDwe0rgW3ApKPfwDl3j3NunnNuXmZmZh98CxJKBSUVTO9gSGOrhYeHNnatepZfWM7E4YkkxviO2Td3dPfmna3cdYjH3yvk+tPHMjmra8MPZ+UkMzo9nqWrOx+Ru2lftYY0ivSTrlTOHgAWHr3RzHKBC4HdIY7puFQ5ExGRPvYeMNHMxppZNIGGH0uPOmY3cB6AmU0lkJyVmllmsKEIZjYOmAhs77fIJeQqapsoPFjHjOzOk7MJwxOZNCKR57ow78w5R35RxTHNQFpNzx5GtNfD+4Xlx71Wc4ufbz9dwMjkWL583sTjHt/KzLhsZjZvbStjf1X7FboWv2NbabWGNIr0k+MmZ86514GD7ez6DfANAhOi+1VC8DdMNWqnLyIifcA51wzcArwAbCDQlXGdmf3AzBYFD/sacIOZ5QOPAZ9xgTbCZwJrzGw18BRws3OuveeoRIgPmoG0P9+srYUzRvLezoOUVjV0elzhwToO1jQe0wykVYzPy4xRw7pUOXvw7V1s2FPJdy+bdvhnpK5aPDsbv4Nn17Rf7dt1oIbGZr8qZyL9pEdzzsxsMVDsnMsPcTxd0jqssVYNQUREpI845551zk1yzo13zv0ouO1259zS4NfrnXOnOedmBVvmvxjc/jfn3PTgtrnOuWfC+X1I7xUEk7Ppx6mcAXzohJH4HTy5orDT41a3NgNpZ75Zq7l5qaw5zmLUeyvq+fWLmzh7ciYXTc86bnxHmzgiiSlZSSzNb39oY2unRi1ALdI/up2cmVk88N/A7V08PuQTnhOCwxrVrVFERET6WkFxJaNS4khLOLY1/dEmZyVx/tTh3P3aNg7VNHZ4XH5hObFRnk7nh3VlMeof/ms9TX7H9xdNx+z4TUDas2h2Nqt2l7e7RtuWYKfGicM1rFGkP/SkcjYeGAvkm9lOApOkV5lZu7+u6YsJz/HBVvq1GtYoIiIifaygpKLDxafb882FU6hpaObOV7Z2eMzqwnJmZCcT5e34R7E5eSlAx01B3thSyj/X7OELZ09gdHpCl+M72mUzswHarZ5t3l/NqJS4bg+XFJGe6XZy5pxb65wb7pwb45wbQ2Dtl7nOua6vuthLH8w5U+VMRERE+k51QzM7ymo6XHy6PRNHJPHxE3N5+O1d7Vajmlr8FBRXdDjfrNXI5DhGdrAYdX1TC995uoCxGQncdNa4LsfWnty0eE4cncoz7SRnW/ZVdbn7o4j0Xlda6T8GvA1MNrMiM7u+78PqXIzPg8egVq30RUREpA9t2FOJc11rBtLWrRdMxAx+9eKmY/Zt2ltFQ7O/w06Nbc3Na38x6nte387OA7V8f9F0YqO83YqtPYtmZbNxbxWb9lYd3tbU4mdbaTUT1alRpN90pVvjlc65kc65KOdcjnPuz0ftH+OcK+u7EI9lZiTE+FQ5ExERkT5VUBzs1NiFZiBtjUyO47Onj+Xp1SWHr9FqdbA9fleSszl5xy5GvetADXe+spUPzRzJmZNCM2XkkhNG4vUYS/M/WM5v14Eamlock4arcibSX3rUrXEgSIj2qXImIiIifaqguJLMpBiGD4vt9rk3nzWelPgofvb8xiO25xeWk54QTU5q3HGv0boY9fvBoY3OOW5fso5or4fbL53W7Zg6kpkUw6nj03kmfw+BFSHUqVEkHCI2OYuP8apyJiIiIn1qXUkFM7rRDKSt5LgobjlnAm9sKeONLR90rF5dWM6s3JQudVdsXYx6VXBo4wvr9vLa5lK+csEkRvQgYezMolnZ7D5Ye7iyt3lfFWaBxbVFpH9EbHKWEO2jRq30RUREpI/UN7WwZX91t5qBHO2aU0aTkxrHT5/biN/vqKpvYmtpdafrm7UV4/MyPbgYdU1DM99/Zj1TRw7j2lNG9zimjlw0I4ton4clqwONQbbsqyY3NZ646N7PaRORronY5Cw+2kuNWumLiIhIH9m4t4oWv+vS4tMdifF5+fqFk1lXUsnS/BLWFlfgHMwOtsnvitbFqH/xwib2VNTzw8tn4OukBX9PDYuN4tzJw/nX2j20+B2b91UxSc1ARPpVxCZnCTE+ajWsUURERPrI4WYg3ezUeLRFs7KZnj2MX764iXd3HARgVk7XE765eYHFqB94aydXnJTLicF5aH1h0exsSqsaeGNLKTvKapio+WYi/SqykzM1BBEREZE+sq6kgpT4KEalHL9xR2c8HuO2i6dQdKiOP762nbEZCaTER3f5/LmjUwBIjY/imwun9CqW4zl3ynASY3z89j9baPY7Jis5E+lXkZucRashiIiIiPSdguJKZmQnd6lxx/GcMTGTMyZmUNfU0q2qGQTa8l85P5effXQmqQldT+p6IjbKy4XTRxxeW01rnIn0r4hNzuLVSl9ERET6SGOzn017q5jeyyGNbX1z4RS8HmP+2PRun/uTj8zkwulZIYulM4tmZQPgMRifqeRMpD/5wh1ATyUEW+k750LyGy0RERGRVlv2V9HY4u/24tOdmTEqmVe/fjYjk0PbAj/UTpuQQVpCNMlxUcRGqVOjSH+K2OQsPtqH30F9k18tXkVERCSk8gsDzUBO6EUb/fbkpsWH9Hp9Icrr4XuLpuP3u3CHIjLkRGxylhATSMhqGpuVnImIiEhI5ReWkxofxej0gZ9M9YXWoY0i0r8ies4ZoHlnIiIiEnL5ReXMyk3R1AkR6VcRm5wltqmciYiIiIRKTUMzm/dVMSsnJdyhiMgQE7HJ2eHKmZIzERERCaG1xRX4HczOTQl3KCIyxERscnZ4zpmGNYqIiEgIrS4sB2CWkjMR6WcRm5y1Vs5qGlQ5ExERkdDJLywnLy2etD5e8FlE5GgRm5wltCZnjaqciYiISOjkF5ZrSKOIhEXEJmfxwWGNmnMmIiIiobK/sp6SinoNaRSRsIjY5CwxpnVYoypnIiIiEhqt881m54Z28WkRka6I2OQsxufBY6qciYiISOisLizH5zGmZys5E5H+F7HJmZmREO1T5UxERERCJr+onCkjk4iN8oY7FBEZgiI2OYPAvDN1axQREZFQ8PsdawortPi0iIRNRCdnCdE+ajSsUUREREJge1k1VQ3N6tQoImET0clZfIyXWrXSFxERkRBYXVgBoORMRMImopOzwJwzVc5ERESGsnd3HGTxXcvID3Za7Kn8wnISY3yMy0wMTWAiIt0U2clZjE+VMxERkSHu5Y37yS8s5+N/fJun3y/u8XVWF5YzMycZr8dCGJ2ISNdFdHIWH+3VnDMREZEhrvBQLSOTY5mTm8KtT6zmJ89toMXvunWN+qYWNuyp1OLTIhJWEZ2cJUT7qFUrfRERkSGt6GAtE4Yn8sjnFnD1yXn88bXtfO7B96isb+ryNdaVVNLsd+rUKCJhddzkzMzuM7P9ZlbQZtsvzGyjma0xs3+YWUqfRtkBtdIXERGRwkN15KTGE+X18MPLT+B/L5/BG1vK+PBdy9hRVtOla7TOV5uTl9J3gYqIHEdXKmcPAAuP2vYSMMM5NxPYDHwrxHF1SWsrfee6N3RBREREBoeahmYO1jSSkxp3eNs1J4/mkc8t4GBNI4vvfJPXN5ce9zr5ReVkDYtlxLDYvgxXRKRTx03OnHOvAweP2vaic661ZLUcyOmD2I4rIcaH30FDsz8cby8iIiJhVnioFoDctPgjtp88Lp2lt5xOdkoc1z3wHmuLKjq9zurCcrXQF5GwC8Wcs88Cz4XgOt2WEOMF0NBGERGRIarwYB0AuW0qZ61y0+J54qZTSI2P5ttPr+2wScihmkZ2HahVMxARCbteJWdm9j9AM/CXTo650cxWmNmK0tLjDyvojvhoH4Da6YuIiAxRRR1Uzlolx0XxnUunkl9UwWPv7m73mNVF5QDMyk3ukxhFRLqqx8mZmX0GuBT4lOtk0pdz7h7n3Dzn3LzMzMyevl27EqKDlTO10xcRERmSCg/WERflJT0husNjFs3K5pRx6fz8+Y2UVTccsz+/sBwzmKlOjSISZj1KzsxsIfANYJFzrja0IXVdfEygcqZhjSIiIkNT4aFactPiMOt44Wgz438vn0FdUws/fnbDMfvzC8uZODyRxODPFSIi4dKVVvqPAW8Dk82syMyuB+4EkoCXzGy1md3dx3G263DlTGudiYiIDEmFB2vJTW1/SGNbE4YncuOZ4/j7qmKWbz9weLtzjtWF5VrfTEQGhK50a7zSOTfSORflnMtxzv3ZOTfBOZfrnJsd/Li5P4I92gdzzlQ5ExERGWqccxQdqutwvtnRbjlnIqNS4vjO0wU0tQQ6PRcerONQbROztb6ZiAwAoejWGDaJh4c1qnImIiIy1JTXNlHd0HzEGmediYv28v1F09myv5o/v7kDgPcLDwGociYiA0JEJ2fxwVb6qpyJiIgMPR2tcdaZ86eN4IJpI/jtv7dQXF5HfmEFMT4Pk7OS+ipMEZEui+jkLCE4rLFGrfRFRESGnA/WOOt6cgbw3cum4XD84Jl15BeVc8KoZKK8Ef0jkYgMEhH9P1FslAczqFW3RhERkSGntXKWk9a1YY2tclLj+dJ5E3lh3T5W7T6kxadFZMCI6OTMzEiI9lGtOWciIiJDTuHBWpLjohgWG9Xtcz93+jgmDE/EOZit5ExEBoiITs4A4qO9mnMmIiIyBBUeqiO3m1WzVtE+Dz/9yAlMHTmMU8anhzgyEZGeifjVFhNjfJpzJiIiMgQVHapl8oieN/KYNyaN5758RggjEhHpncivnMV4NedMRERCzswWmtkmM9tqZre1sz/PzF4xs/fNbI2ZXdJm37eC520ys4v6N/Khwe/v3hpnIiKRIOIrZ/HRPmo0rFFERELIzLzAXcAFQBHwnpktdc6tb3PYt4EnnXN/MLNpwLPAmODXVwDTgWzg32Y2yTmnYR4hVFrdQGOzn9wurnEmIhIJIr5ylhDtpVbDGkVEJLTmA1udc9udc43A48Dio45xwLDg18lASfDrxcDjzrkG59wOYGvwehJChQdbOzWqciYig0fEJ2fxMT6qNaxRRERCaxRQ2OZ1UXBbW98DrjazIgJVsy9241zppcMLUHdzjTMRkYEs4pOzhGgvtWqlLyIi/e9K4AHnXA5wCfCwmXX5uWpmN5rZCjNbUVpa2mdBDlatC1DnaFijiAwikZ+cxWjOmYiIhFwxkNvmdU5wW1vXA08COOfeBmKBjC6ei3PuHufcPOfcvMzMzBCGPjQUHqxleFIMsVHecIciIhIykZ+cRfuobWzBORfuUEREZPB4D5hoZmPNLJpAg4+lRx2zGzgPwMymEkjOSoPHXWFmMWY2FpgIvNtvkQ8RhYdq1alRRAadiE/O4mO8tPgdDc3+cIciIiKDhHOuGbgFeAHYQKAr4zoz+4GZLQoe9jXgBjPLBx4DPuMC1hGoqK0Hnge+oE6NoVd4sE6dGkVk0In4VvoJ0YFvobaxRUMbREQkZJxzzxJo9NF22+1tvl4PnNbBuT8CftSnAQ5hTS1+9lTUkZOqPisiMrhEfuUsOpCQ1ahjo4iIyJCwt6Iev4PcNFXORGRwifjkLCEmUDlTUxAREZGhoXWNM7XRF5HBZvAkZ2qnLyIiMiQcXuNMDUFEZJCJ/OQsOKyxVpUzERGRIaHwYB1ejzEyOTbcoYiIhFTEJ2fx0aqciYiIDCWFh2oZmRyLzxvxP8aIiBwh4v9XS4hR5UxERGQoKTxYq/lmIjIoRXxydrhy1qjKmYiIyFBQeKhOnRpFZFCK+OSstXKmVvoiIiKDX31TC6VVDaqcicigFPHJWVyUFzOoVXImIiIy6BWpU6OIDGIRn5yZGQnRPg1rFBERGQIKD9YBWoBaRAaniE/OAOKjvWoIIiIiMgQcXuNMwxpFZBAaFMlZQoxPrfRFRESGgKJDdUT7PGQkxoQ7FBGRkDtucmZm95nZfjMraLMtzcxeMrMtwc+pfRtm51Q5ExERGRoKD9aSkxqHx2PhDkVEJOS6Ujl7AFh41LbbgP845yYC/wm+DpuEaFXOREREhoLCQ1rjTEQGr+MmZ86514GDR21eDDwY/PpB4PLQhtU98TFealQ5ExERGfQKD2qNMxEZvHo652yEc25P8Ou9wIgQxdMjgTlnSs5EREQGs8r6JirqmlQ5E5FBq9cNQZxzDnAd7TezG81shZmtKC0t7e3btSsh2kutWumLiIgMaoUHtcaZiAxuPU3O9pnZSIDg5/0dHeicu8c5N885Ny8zM7OHb9e5+GhVzkRERAa7w2ucqXImIoNUT5OzpcC1wa+vBZaEJpyeSYgJVM4CRTwREREZjIpa1zjTnDMRGaS60kr/MeBtYLKZFZnZ9cBPgQvMbAtwfvB12MRH+2j2Oxpb/OEMQ0RERPpQ4cFakmJ8JMdFhTsUEZE+4TveAc65KzvYdV6IY+mxhGgvADUNLcT4vGGORkRERPpC4aE6ctLiMdMaZyIyOPW6IchAkBATyDE170xERGTwKjpUS26qhjSKyOA1qJIzdWwUEREZnJxzFB6sI0fNQERkEBsUyVl867BGLUQtIiIyKB2oaaSuqUXNQERkUBsUydnhylmDKmciIiKD0eE1zlQ5E5FBbFAkZ6qciYiIDG6Fh4JrnGkBahEZxAZFcpYQ3TrnTMmZiIjIYFNcXsdj7+zGDHLUEEREBrHjttKPBK3DGqs1rFFERGTQaGrxc/+yHdzx7y34neP7i6YffuaLiAxGg+J/uISYwLDGWrXSFxERGRRW7DzI//yjgE37qjh/6gi+t2iaOjWKyKA3KJKzWJ8XM6hRK30REZGIdrCmkZ8+t4EnVxSRnRzLPdecyIXTs8IdlohIvxgUyZnHY8RHeVU5ExERiWDv7TzIjQ+toKq+mZvOGseXz5tIfPSg+FFFRKRLBs3/ePExPlXOREREIthDb+/CY8a/vnQGk7OSwh2OiEi/GxTdGgESor3q1igiIhLB1hVXMG9MqhIzERmyBk9yFuOjRsMaRUREIlJVfRPby2qYkZ0c7lBERMJm8CRn0T5q1EpfREQkIm3YUwXAjFFKzkRk6Bo0yVl8jIY1ioiIRKqC4goApo8aFuZIRETCZ9AkZwnRaggiIiISqQpKKhieFMPwpNhwhyIiEjaDJjmLj1YrfRERkf6yvqSSNUXlIbveuuJKDWkUkSFv0CRnCWqlLyIi0i+cc9zy2Co++8AKGpp7/+yta2xhy/4qZmRrSKOIDG2DJjmLVyt9ERGRfrGupJLtpTWUVTewdHVJr6+3cW8lfgfTVTkTkSFu0CRnCTE+mloc9U2qnomIiPSlpfklRHmNcRkJ/PnNHTjnenW9gpJKQJ0aRUQGTXI2LTgUYsnq4jBHIiIiMnj5/Y5n8ks4c2ImN589no17q3hr24FeXXNdcQWp8VFkJ6sZiIgMbYMmOTt7UiazcpL5v/9spbHZH+5wREREBqUVuw6xp6KeRbOzWTw7m4zEGP70xvZeXbOgpIIZo5IxsxBFKSISmQZNcmZmfOWCSRSX1/HXlYXhDkdERGRQWrK6mLgoLxdMG0GMz8s1J4/mlU2lbN1f1aPrNTb72bS3iunZGtIoIjJokjOAsyZlMjcvhTtf3qq5ZyIiIiHW1OLn2bV7OH/aCOKjfQBcfXIe0T4Pf35zZ4+uuXlfFU0tjhlafFpEZHAlZ2bGVy+YzJ6Kep54T9UzERGRUHpzaxmHaptYPCv78Lb0xBg+OncUf19VxMGaxm5fc11JBQAzVDkTERlcyRnAaRPSmT82jbteUfVMREQklJauLiE5LoozJ2Uesf2zp42lodnPX5bv6vY1C4orSYrxkZcWH6owRUQi1qBLzgLVs0nsr2rgkR48JERERORYdY0tvLhuLxfPyCLad+SPDxNHJHHWpEwefHtXtxelLiipYFr2MDweNQMRERl0yRnAyePSOXV8One/tk0LU4uIiITAyxv3U9PYwqLZ2e3u/9wZYymrbuCZ/D1dvmZzi58Neyq1vpmISFCvkjMz+4qZrTOzAjN7zMwGzAIlX71gEmXVjTz8tqpnIiLSfWa20Mw2mdlWM7utnf2/MbPVwY/NZlbeZl9Lm31L+zXwPrJkdTHDk2JYMDa93f2nT8hg8ogk/vTG9i4vSr29rIb6Jr+agYiIBPU4OTOzUcCXgHnOuRmAF7giVIH11rwxaZw5KZO7X9tGdYOqZyIi0nVm5gXuAi4GpgFXmtm0tsc4577inJvtnJsN/A74e5vdda37nHOL+ivuvlJR18Srm0q5dGY23g6GH5oZ158+tluLUhcUqxmIiEhbvR3W6APizMwHxAMlvQ8pdL56wSQO1Tbx4Fs7wx2KiIhElvnAVufcdudcI/A4sLiT468EHuuXyMLghXV7aWzxs7iDIY2tFs3OJiMxmj+/uaNL1y0oriQ2ysO4zMRQhCkiEvF6nJw554qBXwK7gT1AhXPuxVAFFgqzc1M4b8pw7nl9O5X1TeEOR0REIscooO2aLEXBbccws9HAWODlNptjzWyFmS03s8v7LMp+snR1CaPT45mZ03mFKzbKy9Unj+bljfvZur/6uNctKKlg2shhHVbjRESGmt4Ma0wl8FvEsUA2kGBmV7dz3I3BB9SK0tLSnkfaQ1+5YBIVdU3c38PFMUVERI7jCuAp51zbNoWjnXPzgKuAO8xs/NEnhfv52FX7q+p5a1sZi2ZlY3b8JOrqk0cHF6XuvHrm9zvWl6gZiIhIW70Z1ng+sMM5V+qcayIw1v7Uow9yzt3jnJvnnJuXmZl5zEX62oxRyVw4bQR/emM7O8tq+v39RUQkIhUDuW1e5wS3tecKjhrSGBxdgnNuO/AqMOfok8L9fOyqZ9fswe9g0azOhzS2ykiM4WMn5vDUykIKD9Z2eNyug7VUNzRrvpmISBu9Sc52AyebWbwFfpV2HrAhNGGF1m0XT8HnNa68dzm7D3T8oBAREQl6D5hoZmPNLJpAAnZM10UzmwKkAm+32ZZqZjHBrzOA04D1/RJ1H1iSX8LUkcOYOCKpy+d86dyJeD3GL1/c1OExrc1ApqtTo4jIYb2Zc/YO8BSwClgbvNY9IYorpMZlJvLI5xZQ29jClfcup+iQEjQREemYc64ZuAV4gcAvHp90zq0zsx+YWdvui1cAj7sje8dPBVaYWT7wCvBT51xEJmeFB2t5f3d5l6tmrbKSY/nsaWNZsrrkcBJ2tIKSCqK9HiYO73rSJyIy2PWqW6Nz7rvOuSnOuRnOuWuccw2hCizUpmcn85fPLaCqvokr711OSXlduEMSEZEBzDn3rHNuknNuvHPuR8FttzvnlrY55nvOuduOOu8t59wJzrlZwc9/7u/YQ2VpfqAJ82WzRnb73JvPHk9qfBQ/fW5ju/vXFVcyOSuJaF9vG0eLiAweQ+p/xBmjknn4+gWU1wQStL0V9eEOSUREZEBqbPbzxHuFzBudSk5qfLfPHxYbxS3nTuTNrWW8vvnIhifOOQpKKrT4tIjIUYZUcgYwKzeFB6+fz4HqRq66dzn7K5WgiYiIHO2xd3ez+2AtXzhnQo+vcfXJeeSkxvHT5zbi938w8rO4vI7y2iamqxmIiMgRhlxyBjA3L5UHrjuJvZX1XHnvckqrBuxoTBERkX5XVd/E//1nCyePS+PsyT3vJBnj8/JfF01m/Z5KluR/0OyyoLgSQG30RUSOMiSTM4B5Y9K4/zMnUVJez1X3LmddSfsTlkVERIaae1/fzoGaRr518dQurW3WmctmZjNj1DB++cJm6psCS8GtK6nA6zGmZKkZiIhIW0M2OQNYMC6dP39mHmXVDVz6uzf51t/XUFatKpqIiAxd+yvrufeNHXxo5khm5ab0+noej3HbwqkUl9fxyPJdQKCN/sThicRGeXt9fRGRwWRIJ2cAp47P4NWvn8N1p47lryuKOOcXr3LP69tobPaHOzQREZF+d8d/ttDU4ue/LpwcsmuePjGDMyZmcOcrW6moa6KgpFLzzURE2jHkkzOA5Pgobr9sGs/feibzxqTy42c3cuFvXuOl9fs4cukaERGRwWtbaTVPvFfIpxbkMSYjIaTX/ubCKZTXNvH9Z9ZRWtWgTo0iIu1QctbGhOGJ3H/dfB647iS8HuOGh1ZwzZ/fZWdZTbhDExER6XM/f34jsT4PXzxvYsivPWNUMpfPzubvq4oPvxYRkSMpOWvH2ZOH8/ytZ/K9y6aRX1TOwt++zn1v7jiiDbCIiMhgsnLXQV5Yt4+bzhpPRmJMn7zH1y6cTLTXgxlMHanKmYjI0ZScdSDK6+Ezp43lpa+cxSnj0vnBP9dzxT3LVUUTEZFBxznHT57dSEZiDNefPrbP3ic3LZ4vnTeBC6eNIDHG12fvIyISqZScHUdWciz3feYkfvGxmWzYW6kqmoiIDDovrd/Hil2HuPX8iST0cdJ0y7kT+eM18/r0PUREIpWSsy4wMz4+L1dVNBERGXSaW/z87PmNjMtI4JMn5YY7HBGRIU3JWTe0V0V78r3CcIclIiLSY39dWcS20hq+sXAyUV79WCAiEk76X7ib2lbR5ual8o2/reFrT+ZT29gc7tBERES6xTnHXa9sZU5eChdNzwp3OCIiQ56Ssx7KSo7l4esX8OXzJvL394u4/K5lbN1fFe6wREREumzV7kMUHarjmpNHY2bhDkdEZMhTctYLXo/xlQsm8dBn53OgupFFdy5jyericIclIiLSJUtWlxDj83ChqmYiIgOCkrMQOGNiJv/60hlMzx7Glx9fzf/8Yy31TS3hDktERKRDzS1+nl27h/Onqq29iMhAoeQsRLKSY3n0hpO56axx/OWd3Xz0D2/xxpZStdwXEZEB6a1tByirbuSyWdnhDkVERIL0q7IQivJ6+NbFU5k/Jo1vPLWGa/78LrlpcVxxUh4fPzGH4cNiwx2iiIgIEBjSmBTr4+zJmeEORUREglQ56wPnTR3BstvO5bdXzCYnJZ5fvLCJU376Mjc+tIJXNu2nRdU0EREJo/qmFl5ct5eF07OIjfKGOxwREQlS5ayPxEZ5WTx7FItnj2JHWQ2Pv7ebp1YU8eL6fYxKieN7i6ZzwbQR4Q5TRESGoFc37aeqoZlFszWkUURkIFHlrB+MzUjgWxdP5e1vncddV80lJT6KGx5awW9e2qw5aSIi0u+WrC4hIzGGU8alhzsUERFpQ8lZP4r2efjQzJH87fOn8tG5Ofz2P1u48eGVVNU3hTs0EREZIqrqm/jPxv1cOnMkPq9+DBARGUj0v3IYxEZ5+eXHZ/K9y6bxyqb9XH7XMraXVoc7LBERGQJeXLePxma/ujSKiAxASs7CxMz4zGljeeT6BRyqbWLxnct4eeO+cIclIiKD3JL8EnJS45iblxLuUERE5ChKzsLslPHpLL3lNPLS47n+wRX87j9bNA9NRET6xIHqBpZtLWPRrGzMLNzhiIjIUZScDQA5qfE8dfOpLJ6Vza9e2syND6+kolbz0EREJLSeXbuHFr9Tl0YRkQFKydkAERft5TefnM3tl07j1U37+dDv3iC/sDzcYYmIyCCyZHUJk0ckMSVrWLhDERGRdvQqOTOzFDN7ysw2mtkGMzslVIENRWbGZ08fy5M3n4Jz8PG73+aht3finIY5iohI7xSX17Fi1yFVzUREBrDeVs5+CzzvnJsCzAI29D4kmZuXyj+/eDqnT8zg9iXruOWx99VuX0REeuWZ/BIALpup5ExEZKDqcXJmZsnAmcCfAZxzjc658hDFNeSlJkTzp0/P47aLp/B8wV4W3bmM9SWV4Q5LREQi1NLVJczJSyEvPT7coYiISAd6UzkbC5QC95vZ+2b2JzNLCFFcAng8xs1njefRzy2gpqGZD/9+GX9dURjusEREJMJs3V/F+j2VLNLaZiIiA1pvkjMfMBf4g3NuDlAD3Hb0QWZ2o5mtMLMVpaWlvXi7oWvBuHSe/fIZnDg6lf96ag3ff2YdzS3+cIclIiIRYunqEjwGH5o5MtyhiIhIJ3qTnBUBRc65d4KvnyKQrB3BOXePc26ec25eZmZmL95uaMtIjOGhz87nM6eO4f5lO/nM/e9RXtsY7rBERCQC/GvtHk4Zn87wpNhwhyIiIp3ocXLmnNsLFJrZ5OCm84D1IYlK2uXzevjeoun8/KMzeWfHARbftYzN+6rCHZaIiAxg9U0tbC+rYf6Y9HCHIiIix9Hbbo1fBP5iZmuA2cCPex2RHNcnTsrl8RtPpqahhQ/ftYwX1+0Nd0giIjJA7TpQi3MwJkONQEREBrpeJWfOudXBIYsznXOXO+cOhSow6dyJo9N45ounMS4zkRsfXsnv/rNF66GJiMgxdpTVADAuIzHMkYiIyPH0tnImYTQyOY6/3nwKi2dn86uXNnPNn99li4Y5iohIG63JmSpnIiIDn5KzCBcb5eWOT87mB4unk19UzsLfvsH3n1lHRa0WrRYREdhRVk1mUgxJsVHhDkVERI5DydkgYGZ8+pQxvPr1s/nkSbk88NZOzvnVq/zlnV20+DXUUURkKNtRVsPYDC1DKiISCZScDSLpiTH8+MMn8M8vns6EzET+5x8FXPa7N3ln+4FwhyYiImGyo6yGcUrOREQigi/cAUjoTc9O5ombTuZfa/fw439t4JP3LCcvLZ7kuCiGxfkCn2OjGBYXxbBYHxdOz2LSiKRwhy0iIiFWUddEWXWjKmciIhFCydkgZWZcOjOb86aM4MG3d7JxTyUVdU1U1jezv7I6+HUT9U1+HnhrJy/ceibpiTHhDltEREJoZ7AZiJIzEZHIoORskIuL9nLzWeM73L++pJLFd73Jt58u4PefmouZ9WN0IiLSlw630c9UciYiEgk052yIm5Y9jK9cMInnCvayZHVJuMMREZEQ2l5Wg8cgN01t9EVEIoGSM+GmM8czNy+F25cUsLeiPtzhiIhIiOwsq2FUahwxPm+4QxERkS5QciZ4PcavPjGbphbHN/+2BufUfl9EZDAItNFPDHcYIiLSRUrOBAhMFv/WJVN4bXMpj767O9zhiIhILznn1EZfRCTCKDmTw65eMJrTJqTzo39tYPeB2nCHIyIivVBa3UB1Q7M6NYqIRBAlZ3KYx2P84mOz8Jrx9b/m0+LX8EYRGbrMbKGZbTKzrWZ2Wzv7f2Nmq4Mfm82svM2+a81sS/Dj2n4NPGhHqdroi4hEGiVncoTslDi+u2g67+48yH1v7gh3OCIiYWFmXuAu4GJgGnClmU1re4xz7ivOudnOudnA74C/B89NA74LLADmA981s9R+DB/4oI2+kjMRkcih5EyO8dG5ozh/6gh+8eImVheWU93QTHOLP9xhiYj0p/nAVufcdudcI/A4sLiT468EHgt+fRHwknPuoHPuEPASsLBPo23HjrIaon0eslPi+vutRUSkh7QItRzDzPjJR07gojte5/K7lh3e7vMYcVFeYqK8xEV7SIuPZlxmIuMzE4KfExmdHk9slFo2i0jEGwUUtnldRKASdgwzGw2MBV7u5NxRfRBjp7aX1TAmPR6vx/r7rUVEpIeUnEm7MpNieOrmU1i2tYz6Jj91TS3UN7UEP/upa2ymtLqB5dsP8I/3iw+fZwY5qXGcNj6D//7QVIbFRoXxuxAR6RdXAE8551q6c5KZ3QjcCJCXlxfyoNSpUUQk8ig5kw6Ny0xkXObx18epaWhmR1kN20qr2V5aw9b91fx1ZRFvbz/AXVfNZcao5H6IVkQkpIqB3Davc4Lb2nMF8IWjzj37qHNfPfok59w9wD0A8+bNC2kHpha/Y/eBWs6bOjyUlxURkT6m5Ex6LSHGx4xRyUckYSt2HuSWR9/nI79/i+9cOpWrTx6NmYbWiEjEeA+YaGZjCSRbVwBXHX2QmU0BUoG322x+AfhxmyYgFwLf6ttwj1RSXkdji1+VMxGRCKOGINIn5o1J49kvn8FpE9L5zpJ13PLo+1TWN4U7LBGRLnHONQO3EEi0NgBPOufWmdkPzGxRm0OvAB53zrk25x4E/pdAgvce8IPgtn6z/XCnxuOPfhARkYFDlTPpM2kJ0fz52pO4543t/OKFTRSUVGiYo4hEDOfcs8CzR227/ajX3+vg3PuA+/osuOPYUVoNqI2+iEikUeVM+pTHY9x81nieuPFkGpv9fOT3b3H3a9soq24Id2giIoPWjrIakmJ8ZCRGhzsUERHpBiVn0i/mjUnjX186g9MnZvDT5zYy/0f/5sp7lvPw8l2UVilRExEJpe1lNYzNTNBcXxGRCKNhjdJvAsMc57FpXxXPrtnDv9bu4TtPF/DdJQXMH5vGh04YyYJx6dQ3tVBV3xz8aDr8dbTPw4fnjCIrOTbc34qIyIC2o6yGE0enHv9AEREZUJScSb8yM6ZkDWNK1jC+csEkNu+r5l9r9/Ds2j18Z8m6457/qxc3sXBGFtedNoa5ean6rbCIyFHqm1ooLq/jYyfmhDsUERHpJiVnEjZmxuSsJCZnJfHVCyaxeV8V60sqSYjxkRQb+BgWG0VijI/EWB97yut56O2dPLGikH+u2cMJo5K59tQxXDpzJLFR3nB/OyIiA8Lug7U4p2YgIiKRSMmZDBiTRiQxaURSh/vz0uP59qXT+MoFk/jH+8U88NZOvv7XfH7y7AY+tSCP604bS2qCJr+LyNC2vbS1jb6SMxGRSKPkTCJOQoyPq08ezacW5LFs6wEeeGsHv3tlK/ct28lnTx/L9aePJTkuqtNrVDc0s2R1Ma9uKiU9IZrctHhyUuPITYsnLy2e9IRoDZkUkYi080AgORuj5ExEJOL0OjkzMy+wAih2zl3a+5BEusbMOH1iBqdPzGDT3iru+Pdm/u8/W7h/2Q5uOGMc1502hqTYI5O0NUXlPPbubpasLqG2sYWc1DjqGls4UNN4xHFxUV5Gp8dz2axsPjEvl8ykmP781kREemxHaQ0ZiTEMi+38l1QiIjLwhKJy9mVgAzAsBNcS6ZHJWUn84eoTWVdSwW9e2sKvX9rMfct2cOOZ4/jY3Bxe2rCPx97dTUFxJbFRHi6bmc2VC/KYk5uCmVHT0EzRoToKD9ZSeKiWwoN1FJRU8IsXNnHHvzdzyQkjuebk0Zw4Wk1IRGRg21FWwzhVzUREIlKvkjMzywE+BPwI+GpIIhLphenZyfzp2nmsKSrn1y9t5ufPb+Lnz28CYEpWEv+7eDqL54w65jfKCTG+w81J2tq6v5pHlu/ibyuLWLK6hKkjh3HNyaO5fE428dEaFSwiA8/2shrOmzI83GGIiEgP9PanyzuAbwAdd3EQCYOZOSk8cN18Vu46xKub9nPulOHMDlbJumPC8ES+t2g6/3XRZJasLuGht3fy3/9Yy0+e28CnFozm+tPHasijiAwYlfVNlFU3MDZTlTMRkUjU4+TMzC4F9jvnVprZ2Z0cdyNwI0BeXl5P306kR04cnRqShVgTYnxctSCPK+fnsmr3Ie5btpM/vr6N+5ft4Mr5edxw5jhGpcSFIGIRkZ7bWaZOjSIikaw3lbPTgEVmdgkQCwwzs0ecc1e3Pcg5dw9wD8C8efNcL95PJOzMjBNHp3Hi6DS2l1Zz92vbeGT5Lh5ZvouPzB3FzWeNZ1xmYrjDFJEhakcwOdOcMxGRyNTj5Mw59y3gWwDBytnXj07MRAazcZmJ/Pxjs/jy+ZO49/XtPPbubp5aWcTCGVmMSomjprGFusYWahqaqW1soaaxmbrGFsYPT+TkcemcPDaNCcMTOxxqWdvYzMpdh3hn+0FW7jpEXlo8nzgpl7l53R+eKSJDw/bSGswgNy0+3KGIiEgPqKOBSC+NSonje4um84VzJnDfsh38ZfkumlocCTFe4qN9xEd7SYjxkRjjIy0+mlW7DvGvNXsAyEiMZv7YNE4el8680Wnsq6rnne0HeWfHAdYWVdDsd3g9xpSsJJ5ZU8ITKwqZODyRT56Uy4fnjCI9UfPdROQDO8pqGJUSR2yUN9yhiIhID4QkOXPOvQq8GopriUSqzKQYvrlwCt9cOKXT45xzFB6sY/n2A4c/nl279/D+KK8xMyeFG88cx4Jx6Zw4OpXEGB/VDc38Mz+QoP3wXxv42fMbuWDaCD55Uh6nT8jA61E1TWSo21FWo/lmIiIRTJUzkX5mZuSlx5OXHhim6Jyj6FAdK3cdIjMphrl5qcRFH/tb78QYH1fMz+OK+Xls3lfFE+8V8vdVRTy7di+xUR4mj0hiWvYwpo4cxrSRw5gychiJMR/8E3fOUVnfzMGaRg5UN3CgppFon4cx6QnkpMYR5fX0520QkRBzzrGzrIaPzB0V7lBERKSHlJyJhJmZkZsW3605IpNGJPGdS6fxjYWTeXnDflbsOsSGPZU8V7CXx94tPHxcXlo88dFeDtY0cqi2kaaW9nvyeD1GTmocY9ITGJMez5iMBJJio6iqb6Kyrpmq+iaq6pupagh8jvF5mZmTzKzcFGblJJMSH93r+yAivVNW3UhVQ7MqZyIiEUzJmUgEi/F5ufiEkVx8wkgg8JvzvZX1bNhTyfqSSjbsqaKhuYVZOSmkJUaTnhBNemI0aQkxpCdEU9/Uwo6yGnYdqGXHgRp2Hahh5a5DVDc0H/E+cVFekmJ9DIuLIinWR0l5Hf/esO/w/tHp8czKSWFWbgqTRySRmhBFSnw0KXFRxEd7u9XAxDlHs99R39RCQ7Of+qYWPGaMTI5VIxSRTrR2ahyrjrEiIhFLyZnIIGJmjEyOY2RyHOdOGdGlc+aNSTvitXOOsupG6hpbSIr1kRjra3fIY2V9EwVFFawuKmdNYQXv7TzI0vySY46L9npIjo8iNT6KuGgfLX4/zS2OphY/zX53+OumFv/hZMzfToEvKdbH1JHDmJ4dGLY5LXsYE4cnEe3TcEwRgB1l1YDa6IuIRDIlZyJyBDMjM+n4XSCHxUZx6oQMTp2QcXjb/sp6tpfVUF7bRHltI+V1TR98XdtETWMzUV4PPo8FPnsNn8dDlNfweY1Yn5fYKC8xPk/gc5SHWJ+XhhY/m/YGqoGPv1tIXVMLEGieMj4zkeHDYslIjCYzMYaMxBgykqLJSIwhNT6auqYWquubqaxvorqhmer6ZqrqA8sbxEZ5SIwNdNJMiPYd7qqZEOMlLtp7bDw+D55g45UWfyCpbGzx09gcSC6bmh1mEO0LfI8+b/B7C36Poar8NTS3sKaognd3HCQxxseF00cwMlmLoA9128tqiPZ6yE7R3wURkUil5ExEQmb4sFiGD4vt0/do8Tt2HqhhfUkl6/dUsmVfFaVVDWzbX01pdQONzf7jXsNjgaGa9c1+Wtor03Ui2uuhxblunweBjp5jMxIYm57AmIwExmYE5veNSU/otPV5azK2fNsBlu84wMpdh6hv+uD7/O7SdczKTWHh9CwWzsjSnKMhakdpDXnp8ercKiISwZSciUhE8XoC1bLxmYlcNiv7iH2tHSnLqhsoq2qgvK6J+GgviTE+kmJ9JMVGkRjjOzwPzjlHQ7P/cEWtuqGZmoZmahqbqW8KDLGsb/LT0Nxy+HVDs/9w5S/aF6iIRfs8RHs9+Lwe/C4wVLPZ76epdfhmsLpWUlHPzrIa/rNxH2XVjUfEHhvlIcrrIcYX+BwVrLpFeT3sPFBzOBmbOnIYV87P4+Rx6cwfk8bB2kZeWLeXFwr28rPnN/Kz5zcyeUQSF83IYsLwxA+aubRp7lJZ30xTix+PGV5P8KPN18OTYvj2pdP67c9UQkNt9EVEIp+SMxEZNMyM5LgokuOiGN+FpghmRmxUYOhiRj8v6F1Z38SusmAjlrIaqhqaPxge2RJI7FqHTJ48Lp1TxgeSsdSEIztjpiZE8//OnsD/O3sCxeV1vFCwl+fX7eV3L2/BtSnueT0WaOoSG2jqEu3z4Pe7YBUQWvyBKqLfQVYfVz8l9Fr8jl0Hajl3yvBwhyIiIr2g5ExEJAyGxUZxQk4yJ+Qkh+yao1Li+OzpY/ns6WMPr2XXmox1t2umRBYDnv3y6Z0OjxURkYFPyZmIyCCUnhhDej9XAyV8PB5jwvCkcIchIiK9pB7UIiIiIiIiA4CSMxERERERkQFAyZmIiIiIiMgAoORMRERERERkAFByJiIiIiIiMgAoORMRERERERkAlJyJiIiIiIgMAErOREREREREBgAlZyIiIiIiIgOAkjMREREREZEBwJxz/fdmZqXArl5eJgMoC0E4g5HuTft0Xzqme9Mx3Zv2dfW+jHbOZfZ1MINFiJ6PoL+3HdF96ZjuTcd0b9qn+9KxXj8j+zU5CwUzW+GcmxfuOAYi3Zv26b50TPemY7o37dN9Gdj059M+3ZeO6d50TPemfbovHQvFvdGwRhERERERkQFAyZmIiIiIiMgAEInJ2T3hDmAA071pn+5Lx3RvOqZ70z7dl4FNfz7t033pmO5Nx3Rv2qf70rFe35uIm3MmIiIiIiIyGEVi5UxERERERGTQiajkzMwWmtkmM9tqZreFO55wMrP7zGy/mRW02ZZmZi+Z2Zbg59RwxhgOZpZrZq+Y2XozW2dmXw5uH9L3xsxizexdM8sP3pfvB7ePNbN3gv+mnjCz6HDHGi5m5jWz983sn8HXujeAme00s7VmttrMVgS3Del/TwORno8f0POxfXo+dkzPyM7p+di+vno+RkxyZmZe4C7gYmAacKWZTQtvVGH1ALDwqG23Af9xzk0E/hN8PdQ0A19zzk0DTga+EPx7MtTvTQNwrnNuFjAbWGhmJwM/A37jnJsAHAKuD1+IYfdlYEOb17o3HzjHOTe7TXvgof7vaUDR8/EYD6DnY3v0fOyYnpGd0/OxYyF/PkZMcgbMB7Y657Y75xqBx4HFYY4pbJxzrwMHj9q8GHgw+PWDwOX9GdNA4Jzb45xbFfy6isB/JqMY4vfGBVQHX0YFPxxwLvBUcPuQuy+tzCwH+BDwp+BrQ/emM0P639MApOdjG3o+tk/Px47pGdkxPR+7rdf/niIpORsFFLZ5XRTcJh8Y4ZzbE/x6LzAinMGEm5mNAeYA76B70zosYTWwH3gJ2AaUO+eag4cM5X9TdwDfAPzB1+no3rRywItmttLMbgxuG/L/ngYYPR+PT39n29Dz8Vh6RnboDvR87EifPB99oYpOBhbnnDOzIduK08wSgb8BtzrnKgO/6AkYqvfGOdcCzDazFOAfwJTwRjQwmNmlwH7n3EozOzvM4QxEpzvnis1sOPCSmW1su3Oo/nuSyDXU/87q+dg+PSOPpefjcfXJ8zGSKmfFQG6b1znBbfKBfWY2EiD4eX+Y4wkLM4si8OD5i3Pu78HNujdBzrly4BXgFCDFzFp/STNU/02dBiwys50EhoOdC/wW3RsAnHPFwc/7CfzAMh/9expo9Hw8Pv2dRc/HrtAz8gh6Pnair56PkZScvQdMDHaIiQauAJaGOaaBZilwbfDra4ElYYwlLIJjof8MbHDO/brNriF9b8wsM/jbQMwsDriAwHyDV4CPBQ8bcvcFwDn3LedcjnNuDIH/V152zn0K3RvMLMHMklq/Bi4EChji/54GID0fj2/I/53V87Fjeka2T8/HjvXl8zGiFqE2s0sIjH31Avc5534U3ojCx8weA84GMoB9wHeBp4EngTxgF/AJ59zRk6IHNTM7HXgDWMsH46P/m8C4+iF7b8xsJoGJqV4Cv5R50jn3AzMbR+C3YWnA+8DVzrmG8EUaXsFhG193zl2qewPBe/CP4Esf8Khz7kdmls4Q/vc0EOn5+AE9H9un52PH9Iw8Pj0fj9SXz8eISs5EREREREQGq0ga1igiIiIiIjJoKTkTEREREREZAJSciYiIiIiIDABKzkRERERERAYAJWciIiIiIiIDgJIzERERERGRAUDJmYiIiIiIyACg5ExERERERGQA+P/xTvIWpY3snAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = np.arange(num_epochs)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15,5))\n",
    "ax[0].plot(epochs, losses)\n",
    "ax[0].set_title('Losses')\n",
    "ax[1].plot(epochs, accuracies)\n",
    "ax[1].set_title('Accuracy');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "num_examples = 100\n",
    "seq_len = 3\n",
    "max_number = 10\n",
    "\n",
    "inputs, targets = get_examples(seq_len, num_examples, max_number)\n",
    "\n",
    "inputs = to_string(inputs, seq_len, max_number)\n",
    "targets = to_string(targets, seq_len, max_number)\n",
    "\n",
    "inputs = integer_encode(inputs, vocab)\n",
    "targets = integer_encode(targets, vocab)\n",
    "\n",
    "inputs, targets = Tensor(np.array(inputs).transpose((1, 0))), Tensor(np.array(targets).transpose((1, 0)))\n",
    "outputs = model(inputs)\n",
    "predicted = np.argmax(outputs.data, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "   <div id=\"5DXq8m\"></div>\n",
       "   <script type=\"text/javascript\" data-lets-plot-script=\"plot\">\n",
       "       (function() {\n",
       "           var plotSpec={\n",
       "\"data\":{\n",
       "\"predicted\":[0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0],\n",
       "\"actual\":[11.0,11.0,11.0,11.0,11.0,11.0,11.0,11.0,11.0,11.0,11.0,11.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,9.0,9.0,9.0,9.0,9.0,9.0,9.0,9.0,9.0,9.0,9.0,9.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,3.0,3.0,3.0,3.0,3.0,3.0,3.0,3.0,3.0,3.0,3.0,3.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
       "\"z\":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,300.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,200.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,31.0,0.0,0.0,1.0,1.0,0.0,0.0,0.0,2.0,0.0,1.0,25.0,0.0,0.0,0.0,1.0,1.0,0.0,1.0,0.0,0.0,0.0,22.0,0.0,0.0,0.0,0.0,3.0,1.0,2.0,0.0,0.0,0.0,34.0,0.0,0.0,0.0,0.0,0.0,3.0,1.0,0.0,0.0,0.0,17.0,6.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.0,14.0,0.0,9.0,2.0,0.0,0.0,0.0,0.0,3.0,3.0,0.0,12.0,3.0,1.0,5.0,0.0,0.0,0.0,0.0,0.0,3.0,3.0,18.0,5.0,1.0,2.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,14.0,6.0,2.0,1.0,1.0,3.0,0.0,0.0,1.0,0.0,0.0,12.0,6.0,4.0,1.0,3.0,3.0,2.0,0.0,0.0,0.0,0.0,0.0]\n",
       "},\n",
       "\"mapping\":{\n",
       "\"x\":\"predicted\",\n",
       "\"y\":\"actual\",\n",
       "\"fill\":\"z\"\n",
       "},\n",
       "\"data_meta\":{\n",
       "},\n",
       "\"theme\":{\n",
       "\"axis_ticks\":\"blank\",\n",
       "\"axis_line\":\"blank\",\n",
       "\"legend_position\":\"none\"\n",
       "},\n",
       "\"ggsize\":{\n",
       "\"width\":500,\n",
       "\"height\":500\n",
       "},\n",
       "\"ggtitle\":{\n",
       "\"text\":\"Confusion matrix\"\n",
       "},\n",
       "\"kind\":\"plot\",\n",
       "\"scales\":[{\n",
       "\"aesthetic\":\"x\",\n",
       "\"discrete\":true,\n",
       "\"reverse\":false\n",
       "},{\n",
       "\"aesthetic\":\"y\",\n",
       "\"discrete\":true,\n",
       "\"reverse\":false\n",
       "}],\n",
       "\"layers\":[{\n",
       "\"geom\":\"raster\",\n",
       "\"mapping\":{\n",
       "},\n",
       "\"data_meta\":{\n",
       "},\n",
       "\"data\":{\n",
       "}\n",
       "},{\n",
       "\"geom\":\"text\",\n",
       "\"mapping\":{\n",
       "\"label\":\"z\"\n",
       "},\n",
       "\"data_meta\":{\n",
       "},\n",
       "\"color\":\"white\",\n",
       "\"data\":{\n",
       "}\n",
       "}]\n",
       "};\n",
       "           var plotContainer = document.getElementById(\"5DXq8m\");\n",
       "           window.letsPlotCall(function() {{\n",
       "               LetsPlot.buildPlotFromProcessedSpecs(plotSpec, -1, -1, plotContainer);\n",
       "           }});\n",
       "       })();    \n",
       "   </script>"
      ],
      "text/plain": [
       "<lets_plot.plot.core.PlotSpec at 0x7f56747cb940>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gg_confusion_matrix(targets.data.reshape(-1), predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def gradient_checker(J, grad_J, theta, eps=1e-5, rtol=1e-5):\n",
    "    \"\"\"Gradient checker for scalar and vector functions\n",
    "Args:\n",
    "    J - function of theta\n",
    "    grad_J - gradient of function J\n",
    "    theta - the point for which to compute the numerical gradient\n",
    "    eps - step value in numerical gradient\n",
    "    rtol - relative tolerance threshold value\n",
    "Returns:\n",
    "    error message if the relative tolerance is greater for some axis\n",
    "    or \"Gradient check passed\" else\n",
    "\"\"\"\n",
    "    it = np.nditer(theta, flags=['multi_index'], op_flags=['readwrite'])\n",
    "\n",
    "    while not it.finished:\n",
    "        ix = it.multi_index\n",
    "        theta_ = np.array(theta, copy=True)\n",
    "        theta_[ix] += eps\n",
    "        J1 = J(theta_)\n",
    "        theta_ = np.array(theta, copy=True)\n",
    "        theta_[ix] -= eps\n",
    "        J2 = J(theta_)\n",
    "\n",
    "        J1 = to_scalar(J1, ix)\n",
    "        J2 = to_scalar(J2, ix)\n",
    "\n",
    "        num_grad = (J1 - J2)/(2*eps)\n",
    "\n",
    "        rel_tol = np.abs(num_grad - grad_J)[ix]/(1. + np.minimum(np.abs(num_grad), np.abs(grad_J[ix])))\n",
    "\n",
    "        if rel_tol > rtol:\n",
    "            print(f'num_grad: {num_grad} grad: {grad_J[ix]} factor: {grad_J[ix] / num_grad}')\n",
    "            print(f'Incorrect gradient for the axis {str(ix)}')\n",
    "            return\n",
    "        it.iternext()\n",
    "    print(f'Gradient check passed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def J_theta_global(model, loss_function, theta, idx, x, y):\n",
    "    original = model.parameters[idx].data.copy()\n",
    "    np.copyto(dst=model.parameters[idx].data, src=theta)\n",
    "    outputs = model(x)\n",
    "    loss_value = loss_function(outputs, y).data\n",
    "    np.copyto(dst=model.parameters[idx].data, src=original)\n",
    "    model.zero_grad()\n",
    "    return loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def dJ_theta_global(model, loss_function, x, y):\n",
    "    outputs = model(x)\n",
    "    loss = loss_function(outputs, y)\n",
    "    loss.backward()\n",
    "    grads = []\n",
    "    for parameter in model.parameters:\n",
    "        grads.append(parameter.grad.copy())\n",
    "    model.zero_grad()\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "num_examples = 100\n",
    "seq_len = 2\n",
    "max_number = 10\n",
    "vocab_size = len(vocab)\n",
    "emb_size = 20\n",
    "hidden_size = 32\n",
    "\n",
    "X_val, y_val = get_examples(seq_len, num_examples, max_number)\n",
    "X_val, y_val = X_val.transpose(1, 0), y_val.transpose(1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]: Start -- E\n",
      "Gradient check passed\n",
      "[0]: Elapsed time: 0.3s\n",
      "[1]: Start -- weights\n",
      "Gradient check passed\n",
      "[1]: Elapsed time: 1.9s\n",
      "[2]: Start -- bias\n",
      "Gradient check passed\n",
      "[2]: Elapsed time: 0.0s\n",
      "[3]: Start -- weights\n",
      "Gradient check passed\n",
      "[3]: Elapsed time: 0.4s\n",
      "[4]: Start -- bias\n",
      "Gradient check passed\n",
      "[4]: Elapsed time: 0.0s\n",
      "Total elapsed time: 2.7s\n"
     ]
    }
   ],
   "source": [
    "loss_function = CrossEntropyLoss()\n",
    "model_ = RecurrentNetwork(vocab_size, emb_size, hidden_size)\n",
    "dJ_theta_tensors = dJ_theta_global(model_, loss_function, Tensor(X_val), Tensor(y_val))\n",
    "global_start = time.time()\n",
    "for i, parameter in enumerate(model_.parameters):\n",
    "    start = time.time()\n",
    "    print(f'[{i}]: Start -- {parameter.__name__}')\n",
    "    def J_theta(theta, idx=i, x=Tensor(X_val), y=Tensor(y_val)):\n",
    "        return J_theta_global(model_, loss_function, theta, idx, x, y)\n",
    "    gradient_checker(J_theta, dJ_theta_tensors[i], parameter.data)\n",
    "    print(f'[{i}]: Elapsed time: {time.time() - start:.1f}s')\n",
    "print(f'Total elapsed time: {time.time() - global_start:.1f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "sheet_delimiter": true,
     "type": "MD"
    }
   },
   "source": [
    "# 1. LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "### Problem 1 (6.0)\n",
    "\n",
    "Implement the LSTM cell class and use it in the RNN sorter. Don't forget to check gradients!\n",
    "\n",
    "LSTM cell formulas:\n",
    "$$\n",
    "f_t=\\sigma\\Bigg(W_f\\cdot\\Big[h_{t-1};x_t\\Big] + b_f\\Bigg)\\\\\n",
    "i_t = \\sigma\\Bigg(W_i\\cdot\\Big[h_{t-1};x_t\\Big] + b_i\\Bigg)\\\\\n",
    "\\tilde{c}_t = \\tanh\\Bigg(W_c\\cdot\\Big[h_{t-1};x_t\\Big] + b_c\\Bigg)\\\\\n",
    "c_t = f_t \\ast c_{t-1} + i_t \\ast \\tilde{c}_t\\\\\n",
    "o_t = \\sigma\\Bigg(W_o\\cdot\\Big[h_{t-1};x_t\\Big] + b_o\\Bigg)\\\\\n",
    "h_t = o_t \\ast \\tanh \\left(c_t\\right)\n",
    "$$\n",
    "\n",
    "As you can see, you'll need two additional functions here: sum and multiplication. You have to implement them too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "class MultiplyFunction(Function):\n",
    "    def __init__(self, x1: Tensor, x2: Tensor):\n",
    "        self.x1 = x1\n",
    "        self.x2 = x2\n",
    "\n",
    "    def __call__(self):\n",
    "        product = np.multiply(self.x1.data, self.x2.data)\n",
    "        return Tensor(product, func=self, name='multiply')\n",
    "\n",
    "    def backward(self, grad: np.ndarray):\n",
    "        grad = grad.reshape(self.x1.shape)\n",
    "        self.x1.backward(np.multiply(grad, self.x2.data))\n",
    "        self.x2.backward(np.multiply(grad, self.x1.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "class Multiply(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x1: Tensor, x2: Tensor):\n",
    "        return MultiplyFunction(x1, x2)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "class SumFunction(Function):\n",
    "    def __init__(self, x1: Tensor, x2: Tensor):\n",
    "        self.x1 = x1\n",
    "        self.x2 = x2\n",
    "\n",
    "    def __call__(self):\n",
    "        output = np.add(self.x1.data, self.x2.data)\n",
    "        return Tensor(output, func=self, name='sum')\n",
    "        \n",
    "\n",
    "    def backward(self, grad: np.ndarray):\n",
    "        grad = grad.reshape(self.x1.shape)\n",
    "        self.x1.backward(grad)\n",
    "        self.x2.backward(grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "class Sum(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x1: Tensor, x2: Tensor):\n",
    "        return SumFunction(x1, x2)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "class LSTMCell(Module):\n",
    "    def __init__(self, state_size: int, hidden_size: int):\n",
    "        super().__init__()\n",
    "        \n",
    "        # modules w/o weights -- can use for multiple operations\n",
    "        self.hstack = HStack()\n",
    "        self.mult = Multiply()\n",
    "        self.sum = Sum()\n",
    "        self.tanh = TanhFunction()\n",
    "        self.sigmoid = SigmoidFunction()\n",
    "\n",
    "        # linear layers\n",
    "        self.forget_linear = LinearLayer(state_size, hidden_size)\n",
    "        self.info_linear = LinearLayer(state_size, hidden_size)\n",
    "        self.candidate_linear = LinearLayer(state_size, hidden_size)\n",
    "        self.output_linear = LinearLayer(state_size, hidden_size)\n",
    "        self.register_parameters([self.forget_linear, self.info_linear,\n",
    "                                  self.candidate_linear, self.output_linear])\n",
    "\n",
    "    def forward(self, x: Tensor, h_t_1: Tensor, c_t_1: Tensor):\n",
    "        stack = self.hstack(h_t_1, x)\n",
    "        f_t = self.sigmoid(self.forget_linear(stack))\n",
    "        i_t = self.sigmoid(self.info_linear(stack))\n",
    "        ct_t = self.tanh(self.candidate_linear(stack))\n",
    "        c_t = self.sum(self.mult(f_t, c_t_1), self.mult(i_t, ct_t))\n",
    "        o_t = self.sigmoid(self.output_linear(stack))\n",
    "        h_t = self.mult(o_t, self.tanh(c_t))\n",
    "        return h_t, c_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "class LSTM(Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.state_size = input_size + hidden_size\n",
    "        self.lstm = LSTMCell(self.state_size, self.hidden_size)\n",
    "        self.row = Row()\n",
    "        self.vstack = VStack()\n",
    "        self.register_parameters([self.lstm])\n",
    "\n",
    "    def forward(self, x: Tensor, h_t_1: Optional[Tensor] = None, c_t_1: Optional[Tensor] = None):\n",
    "        seq_len, batch_size, input_size = x.shape\n",
    "        h = Tensor(np.zeros((0, batch_size, self.hidden_size)), name=\"h\")\n",
    "        if h_t_1 is None:\n",
    "            h_t_1 = Tensor(np.zeros((batch_size, self.hidden_size)), name=\"h_t_1\")\n",
    "        if c_t_1 is None:\n",
    "            c_t_1 = Tensor(np.zeros((batch_size, self.hidden_size)), name=\"c_t_1\")\n",
    "        for idx in range(seq_len):\n",
    "            h_t_1, c_t_1 = self.lstm.forward(self.row(x, idx), h_t_1, c_t_1)\n",
    "            h = self.vstack(h, h_t_1.reshape((1, batch_size, self.hidden_size)))\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "sheet_delimiter": true,
     "type": "MD"
    }
   },
   "source": [
    "# Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "class Adam(Optimizer):\n",
    "    def __init__(self, params: List[Tensor], lr: float = 0.001, alpha: float = 0.1,\n",
    "                 beta1: float = 0.9, beta2: float = 0.999, eps: float = 1e-8,\n",
    "                 weight_decay: float = 0.01):\n",
    "        super().__init__(params, lr)\n",
    "        self.alpha = alpha\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.eps = eps\n",
    "        self.weight_decay = weight_decay\n",
    "        self.m = [np.zeros_like(p.grad) for p in params]\n",
    "        self.v = [np.zeros_like(p.grad) for p in params]\n",
    "        self.t = 0\n",
    "\n",
    "    def step(self):\n",
    "        for i, param in enumerate(self.params):\n",
    "            g = param.grad\n",
    "            self.t += 1\n",
    "            self.m[i] = self.beta1 * self.m[i] + (1 - self.beta1) * g\n",
    "            self.v[i] = self.beta2 * self.v[i] + (1 - self.beta2) * g**2\n",
    "            m_hat = self.m[i] / (1 - self.beta1**self.t)\n",
    "            sqrt_v_hat = np.sqrt(self.v[i] / (1 - self.beta2**self.t))\n",
    "            eta = self.lr\n",
    "            param.data -= eta * (\n",
    "                self.alpha * m_hat / (sqrt_v_hat + self.eps) +\n",
    "                self.weight_decay * param.data\n",
    "            )\n",
    "\n",
    "    def zero_grad(self):\n",
    "        super().zero_grad()\n",
    "        for lst in [self.m, self.v]:\n",
    "            for tensor in lst:\n",
    "                tensor[:] = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "sheet_delimiter": true,
     "type": "MD"
    }
   },
   "source": [
    "# Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "# Checks\n",
    "Change RNN to LSTM in the RecurrentNetwork class below to perform gradient check.\n",
    "Note, that due to naive implementation of the backpropagation, number of calculations needed for one backpropagation pass grows exponentially with respect to sequence length. That's why the length in the gradient check is set to 2.\n",
    "\n",
    "$\\color{red}{\\text{If you want to implement a faster version of numpy framework, which supports recurrent arcgitectures, you can take this task as a course project.}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "class RecurrentNetwork(Module):\n",
    "    def __init__(self, vocab_size: int, emb_size: int, hidden_size: int):\n",
    "        super().__init__()\n",
    "        self.emb_size = emb_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = Embedding(vocab_size, emb_size)\n",
    "        self.lstm = LSTM(emb_size, hidden_size)\n",
    "        self.linear = LinearLayer(hidden_size, vocab_size)\n",
    "        xavier_(self.linear.parameters)\n",
    "        self.register_parameters([self.embedding, self.lstm, self.linear])\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        emb = self.embedding(x)\n",
    "        lstm_out = self.lstm(emb)\n",
    "        linear_out = self.linear(lstm_out.reshape(-1, self.hidden_size))\n",
    "        return linear_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def gradient_checker(J, grad_J, theta, eps=1e-5, rtol=1e-5):\n",
    "    \"\"\"Gradient checker for scalar and vector functions\n",
    "Args:\n",
    "    J - function of theta\n",
    "    grad_J - gradient of function J\n",
    "    theta - the point for which to compute the numerical gradient\n",
    "    eps - step value in numerical gradient\n",
    "    rtol - relative tolerance threshold value\n",
    "Returns:\n",
    "    error message if the relative tolerance is greater for some axis\n",
    "    or \"Gradient check passed\" else\n",
    "\"\"\"\n",
    "    it = np.nditer(theta, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    calls = 0 \n",
    "    while not it.finished:\n",
    "        ix = it.multi_index\n",
    "        theta_ = np.array(theta, copy=True)\n",
    "        theta_[ix] += eps\n",
    "        J1 = J(theta_)\n",
    "        theta_ = np.array(theta, copy=True)\n",
    "        theta_[ix] -= eps\n",
    "        J2 = J(theta_)\n",
    "        calls += 1\n",
    "        J1 = to_scalar(J1, ix)\n",
    "        J2 = to_scalar(J2, ix)\n",
    "\n",
    "        num_grad = (J1 - J2)/(2*eps)\n",
    "\n",
    "        rel_tol = np.abs(num_grad - grad_J)[ix]/(1. + np.minimum(np.abs(num_grad), np.abs(grad_J[ix])))\n",
    "\n",
    "        if rel_tol > rtol:\n",
    "            print(f'num_grad: {num_grad} grad: {grad_J[ix]} factor: {grad_J[ix] / num_grad}')\n",
    "            print(f'Incorrect gradient for the axis {str(ix)}')\n",
    "            print(f'calls: {calls}')\n",
    "            return\n",
    "        it.iternext()\n",
    "    print(f'Gradient check passed. Calls: {calls}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def J_theta_global(model, loss_function, theta, idx, x, y):\n",
    "    original = model.parameters[idx].data.copy()\n",
    "    np.copyto(dst=model.parameters[idx].data, src=theta)\n",
    "    outputs = model(x)\n",
    "    loss_value = loss_function(outputs, y).data\n",
    "    np.copyto(dst=model.parameters[idx].data, src=original)\n",
    "    model.zero_grad()\n",
    "    return loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "def dJ_theta_global(model, loss_function, x, y):\n",
    "    outputs = model(x)\n",
    "    loss = loss_function(outputs, y)\n",
    "    loss.backward()\n",
    "    grads = []\n",
    "    for parameter in model.parameters:\n",
    "        grads.append(parameter.grad.copy())\n",
    "    model.zero_grad()\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "# original - passes test\n",
    "num_examples = 100\n",
    "seq_len = 2\n",
    "max_number = 10\n",
    "vocab_size = len(vocab)\n",
    "emb_size = 20\n",
    "hidden_size = 32\n",
    "\n",
    "X_val, y_val = get_examples(seq_len, num_examples, max_number)\n",
    "X_val, y_val = X_val.transpose(1, 0), y_val.transpose(1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]: Start -- E\n",
      "Gradient check passed. Calls: 240\n",
      "[0]: Elapsed time: 0.6s\n",
      "[1]: Start -- weights\n",
      "Gradient check passed. Calls: 1664\n",
      "[1]: Elapsed time: 4.5s\n",
      "[2]: Start -- bias\n",
      "Gradient check passed. Calls: 32\n",
      "[2]: Elapsed time: 0.1s\n",
      "[3]: Start -- weights\n",
      "Gradient check passed. Calls: 1664\n",
      "[3]: Elapsed time: 4.6s\n",
      "[4]: Start -- bias\n",
      "Gradient check passed. Calls: 32\n",
      "[4]: Elapsed time: 0.1s\n",
      "[5]: Start -- weights\n",
      "Gradient check passed. Calls: 1664\n",
      "[5]: Elapsed time: 4.6s\n",
      "[6]: Start -- bias\n",
      "Gradient check passed. Calls: 32\n",
      "[6]: Elapsed time: 0.1s\n",
      "[7]: Start -- weights\n",
      "Gradient check passed. Calls: 1664\n",
      "[7]: Elapsed time: 4.6s\n",
      "[8]: Start -- bias\n",
      "Gradient check passed. Calls: 32\n",
      "[8]: Elapsed time: 0.1s\n",
      "[9]: Start -- weights\n",
      "Gradient check passed. Calls: 384\n",
      "[9]: Elapsed time: 0.9s\n",
      "[10]: Start -- bias\n",
      "Gradient check passed. Calls: 12\n",
      "[10]: Elapsed time: 0.0s\n",
      "Total elapsed time: 20.3s\n"
     ]
    }
   ],
   "source": [
    "loss_function = CrossEntropyLoss()\n",
    "model_ = RecurrentNetwork(vocab_size, emb_size, hidden_size)\n",
    "dJ_theta_tensors = dJ_theta_global(model_, loss_function, Tensor(X_val), Tensor(y_val))\n",
    "global_start = time.time()\n",
    "for i, parameter in enumerate(model_.parameters):\n",
    "    start = time.time()\n",
    "    print(f'[{i}]: Start -- {parameter.__name__}')\n",
    "    def J_theta(theta, idx=i, x=Tensor(X_val), y=Tensor(y_val)):\n",
    "        return J_theta_global(model_, loss_function, theta, idx, x, y)\n",
    "    gradient_checker(J_theta, dJ_theta_tensors[i], parameter.data)\n",
    "    print(f'[{i}]: Elapsed time: {time.time() - start:.1f}s')\n",
    "print(f'Total elapsed time: {time.time() - global_start:.1f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test LSTM performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, targets = get_examples(seq_len, num_examples, max_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "vocab_size = len(vocab)\n",
    "emb_size = 20\n",
    "hidden_size = 32\n",
    "batch_size = 100\n",
    "dataloader = DataLoader(inputs, targets, batch_size=batch_size)\n",
    "model = RecurrentNetwork(vocab_size, emb_size, hidden_size)\n",
    "loss_function = CrossEntropyLoss()\n",
    "optimizer = SGD(model.parameters, lr=1.0)\n",
    "#optimizer = Adam(model.parameters, alpha=0.1, beta1=0.9, beta2=0.999, eps=1e-8, weight_decay=0.01)\n",
    "scheduler = ConstantLR(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7420"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " epoch: [100/100], loss: 1.3102336841359534, acc: 0.635"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "accuracies = []\n",
    "lrs = []\n",
    "for epoch in range(num_epochs):\n",
    "    loss_sum = 0\n",
    "    for data in dataloader():\n",
    "        optimizer.zero_grad()\n",
    "        inputs, targets = data\n",
    "        inputs = inputs.transpose(1, 0)\n",
    "        targets = targets.transpose(1, 0)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_sum += loss.data\n",
    "    acc = eval_accuracy(model, inputs.data, targets.data)\n",
    "    print(f'\\r epoch: [{epoch+1}/{num_epochs}], loss: {loss_sum}, acc: {acc}', end='')\n",
    "    losses.append(loss_sum)\n",
    "    accuracies.append(acc)\n",
    "    lrs.append(scheduler.lr)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = np.arange(num_epochs)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15,5))\n",
    "ax[0].plot(epochs, losses)\n",
    "ax[0].set_title('Losses')\n",
    "ax[1].plot(epochs, accuracies)\n",
    "ax[1].set_title('Accuracy');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = 100\n",
    "seq_len = 3\n",
    "max_number = 10\n",
    "\n",
    "inputs, targets = get_examples(seq_len, num_examples, max_number)\n",
    "\n",
    "inputs = to_string(inputs, seq_len, max_number)\n",
    "targets = to_string(targets, seq_len, max_number)\n",
    "\n",
    "inputs = integer_encode(inputs, vocab)\n",
    "targets = integer_encode(targets, vocab)\n",
    "\n",
    "inputs, targets = Tensor(np.array(inputs).transpose((1, 0))), Tensor(np.array(targets).transpose((1, 0)))\n",
    "outputs = model(inputs)\n",
    "predicted = np.argmax(outputs.data, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "   <div id=\"kbtlju\"></div>\n",
       "   <script type=\"text/javascript\" data-lets-plot-script=\"plot\">\n",
       "       (function() {\n",
       "           var plotSpec={\n",
       "\"data\":{\n",
       "\"predicted\":[0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0],\n",
       "\"actual\":[11.0,11.0,11.0,11.0,11.0,11.0,11.0,11.0,11.0,11.0,11.0,11.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,10.0,9.0,9.0,9.0,9.0,9.0,9.0,9.0,9.0,9.0,9.0,9.0,9.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,8.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,7.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,6.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,5.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,4.0,3.0,3.0,3.0,3.0,3.0,3.0,3.0,3.0,3.0,3.0,3.0,3.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
       "\"z\":[0.0,0.0,0.0,0.0,33.0,0.0,21.0,14.0,158.0,74.0,0.0,0.0,10.0,0.0,0.0,18.0,24.0,15.0,20.0,16.0,74.0,23.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,3.0,0.0,0.0,22.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,4.0,0.0,21.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,4.0,2.0,5.0,11.0,3.0,2.0,0.0,0.0,0.0,0.0,0.0,0.0,4.0,1.0,16.0,1.0,7.0,3.0,0.0,0.0,1.0,0.0,0.0,1.0,0.0,10.0,2.0,3.0,17.0,1.0,0.0,0.0,2.0,0.0,0.0,0.0,10.0,5.0,2.0,3.0,5.0,4.0,0.0,0.0,4.0,0.0,1.0,12.0,6.0,2.0,3.0,1.0,5.0,5.0,0.0,0.0,6.0,0.0,1.0,3.0,6.0,1.0,0.0,2.0,6.0,1.0,0.0,0.0,6.0,0.0,0.0,1.0,0.0,1.0,2.0,2.0,6.0,3.0,0.0,0.0,15.0,0.0,0.0,3.0,5.0,5.0,3.0,0.0,4.0,3.0,0.0,0.0]\n",
       "},\n",
       "\"mapping\":{\n",
       "\"x\":\"predicted\",\n",
       "\"y\":\"actual\",\n",
       "\"fill\":\"z\"\n",
       "},\n",
       "\"data_meta\":{\n",
       "},\n",
       "\"theme\":{\n",
       "\"axis_ticks\":\"blank\",\n",
       "\"axis_line\":\"blank\",\n",
       "\"legend_position\":\"none\"\n",
       "},\n",
       "\"ggsize\":{\n",
       "\"width\":500,\n",
       "\"height\":500\n",
       "},\n",
       "\"ggtitle\":{\n",
       "\"text\":\"Confusion matrix\"\n",
       "},\n",
       "\"kind\":\"plot\",\n",
       "\"scales\":[{\n",
       "\"aesthetic\":\"x\",\n",
       "\"discrete\":true,\n",
       "\"reverse\":false\n",
       "},{\n",
       "\"aesthetic\":\"y\",\n",
       "\"discrete\":true,\n",
       "\"reverse\":false\n",
       "}],\n",
       "\"layers\":[{\n",
       "\"geom\":\"raster\",\n",
       "\"mapping\":{\n",
       "},\n",
       "\"data_meta\":{\n",
       "},\n",
       "\"data\":{\n",
       "}\n",
       "},{\n",
       "\"geom\":\"text\",\n",
       "\"mapping\":{\n",
       "\"label\":\"z\"\n",
       "},\n",
       "\"data_meta\":{\n",
       "},\n",
       "\"color\":\"white\",\n",
       "\"data\":{\n",
       "}\n",
       "}]\n",
       "};\n",
       "           var plotContainer = document.getElementById(\"kbtlju\");\n",
       "           window.letsPlotCall(function() {{\n",
       "               LetsPlot.buildPlotFromProcessedSpecs(plotSpec, -1, -1, plotContainer);\n",
       "           }});\n",
       "       })();    \n",
       "   </script>"
      ],
      "text/plain": [
       "<lets_plot.plot.core.PlotSpec at 0x7f56747be940>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gg_confusion_matrix(targets.data.reshape(-1), predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "sheet_delimiter": true,
     "type": "MD"
    }
   },
   "source": [
    "# 2. Distillation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "# Problem 2 (6.0) Model Distillation\n",
    "\n",
    "На лекции мы упоминали Model Distillation в контексте DistillBert от HuggingFace. В этом задании вам предлагается применить дистилляцию к произвольной модели и попробовать добиться сокращения размера модели-ученика при почти полном сохранении качества по сравнению с моделью-учителем.\n",
    "\n",
    "Посмотрите следующее [руководство](https://habr.com/ru/company/avito/blog/485290/) и попробуйте применить описанные идеи к какой-либо модели. Не обязательно брать BERT, вполне подойдет BiLSTM или что-то подобное, для чего известны метрики на каком-либо датасете.\n",
    "\n",
    "Ссылки на GitHub или Colab c решением размещайте на этой странице. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "sheet_delimiter": true,
     "type": "MD"
    }
   },
   "source": [
    "# DUE DATE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "MD"
    }
   },
   "source": [
    "# The due date is 22 of December 2021 23:59:59\n",
    "\n",
    "## Instructions\n",
    "\n",
    "* To submit the assignment share your workbook to me (with **Can edit** access rights).\n",
    "\n",
    "* Check, that you found all the tasks in the workbook.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "datalore": {
   "computation_mode": "JUPYTER",
   "packages": [],
   "version": 1
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
