{"cells":[{"cell_type":"markdown","metadata":{"id":"8F1UvGuxHkAB"},"source":["# SVM и его ядра\n","__Суммарное количество баллов: 9__\n","\n","__Решение отправлять на `ml.course.practice@gmail.com`__\n","\n","__Тема письма: `[HSE][ML][MS][HW07] <ФИ>`, где вместо `<ФИ>` указаны фамилия и имя__\n","\n","В этом задании нам предстоит решить задачу SVM при помощи `cvxopt` и применить ее к искуственным данным. Затем аналогичным способом нужно будет решить задачу ядерного SVM и исследовать его поведение для различных ядер и значений их параметров."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"67NDiPsbHkAD"},"outputs":[],"source":["import numpy as np\n","import copy\n","from cvxopt import spmatrix, matrix, solvers\n","import matplotlib.pyplot as plt\n","from sklearn.datasets import make_classification, make_moons, make_blobs\n","from typing import NoReturn, Callable\n","\n","solvers.options['show_progress'] = False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6MMMt-YWHkAJ"},"outputs":[],"source":["def visualize(clf, X, y):\n","    x_min, x_max = X[:, 0].min(), X[:, 0].max()\n","    y_min, y_max = X[:, 1].min(), X[:, 1].max()\n","    x_border = (x_max - x_min) / 20 + 1.0e-3\n","    x_h = (x_max - x_min + 2 * x_border) / 200\n","    y_border = (y_max - y_min) / 20 + 1.0e-3\n","    y_h = (y_max - y_min + 2 * y_border) / 200\n","    \n","    cm = plt.cm.Spectral\n","\n","    xx, yy = np.meshgrid(np.arange(x_min - x_border, x_max + x_border, x_h), np.arange(y_min - y_border, y_max + y_border, y_h))\n","    mesh = np.c_[xx.ravel(), yy.ravel()]\n","\n","    z_class = clf.predict(mesh).reshape(xx.shape)\n","\n","    # Put the result into a color plot\n","    plt.figure(1, figsize=(8, 8))\n","    plt.pcolormesh(xx, yy, z_class, cmap=cm, alpha=0.3, shading='gouraud')\n","\n","    # Plot hyperplane and margin\n","    z_dist = clf.decision_function(mesh).reshape(xx.shape)\n","    plt.contour(xx, yy, z_dist, [0.0], colors='black')\n","    plt.contour(xx, yy, z_dist, [-1.0, 1.0], colors='black', linestyles='dashed')\n","\n","    # Plot also the training points\n","    y_pred = clf.predict(X)\n","\n","    ind_support = []\n","    ind_correct = []\n","    ind_incorrect = []\n","    for i in range(len(y)):\n","        if i in clf.support:\n","            ind_support.append(i)\n","        elif y[i] == y_pred[i]:\n","            ind_correct.append(i)\n","        else:\n","            ind_incorrect.append(i)\n","\n","    plt.scatter(X[ind_correct, 0], X[ind_correct, 1], c=y[ind_correct], cmap=cm, alpha=1., edgecolor='black', linewidth=.8)\n","    plt.scatter(X[ind_incorrect, 0], X[ind_incorrect, 1], c=y[ind_incorrect], cmap=cm, alpha=1., marker='*',\n","               s=50, edgecolor='black', linewidth=.8)\n","    plt.scatter(X[ind_support, 0], X[ind_support, 1], c=y[ind_support], cmap=cm, alpha=1., edgecolor='yellow', linewidths=1.,\n","               s=40)\n","\n","    plt.xlim(xx.min(), xx.max())\n","    plt.ylim(yy.min(), yy.max())\n","    plt.tight_layout()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"keCF5JnaHkAN"},"outputs":[],"source":["def generate_dataset(moons=False):\n","    if moons:\n","        X, y = make_moons(1000, noise=0.075, random_state=42)\n","        return X, 2 * y - 1\n","    X, y = make_blobs(1000, 2, centers=[[0, 0], [-4, 2], [3.5, -2.0], [3.5, 3.5]], random_state=42)\n","    y = 2 * (y % 2) - 1\n","    return X, y\n","\n","X, y = generate_dataset(True)"]},{"cell_type":"markdown","metadata":{"id":"vK9yV9v5HkAQ"},"source":["### Задание 1 (2 балла)\n","Для начала реализуем обычный линейный SVM. \n","\n","#### Методы\n","`fit(X, y)` - обучает SVM, решая задачу оптимизации при помощи `cvxopt.solvers.qp`\n","\n","`decision_function(X)` - возвращает значение решающей функции (т.е. то число, от которого берем знак с целью узнать класс)\n","\n","#### Поля\n","`support` - индексы опорных элементов"]},{"cell_type":"markdown","metadata":{"id":"9iPV3I3bjPkp"},"source":["### Решение с помощью QP Solver\n","\n","QP-solver решает такую задачу:\n","\n","$\\begin{cases}0.5 \\cdot x^\\text{T}Px + q^\\text{T}x\\rightarrow \\min_x\\\\Gx \\leq h\\\\Ax=b\\end{cases}$\n","\n","А наша задача формулируется так:\n","\n","$\\begin{cases}0.5 \\cdot w^\\text{T}w + C \\cdot \\sum \\xi_i \\rightarrow \\min_{w, \\xi} \\\\ \\xi \\geq 0 \\\\ y_i (w^\\text{T}x_i + w_0) \\geq 1 - \\xi_i \\end{cases}$\n","\n","Сведем ее к задаче QP-solver'а:\n","\n","$ x = (w, w_0, \\xi) \\\\ P = \n","\\left[\n","    \\begin{array}{c|c}\n","      I & 0\\\\\n","      \\hline\n","      0 & 0\n","    \\end{array}\n","\\right] \\\\ \n","q = \\left[\n","    \\begin{array}{c}\n","      0 \\\\\n","      \\hline\n","      C \n","    \\end{array}\n","\\right] \\\\ \n"," G = \n","\\left[\n","    \\begin{array}{c|c|c}\n","      0 & 0 & -I\\\\\n","      \\hline\n","      -yX & -y & -I\n","    \\end{array}\n","\\right] \\\\ h = \\left[\n","    \\begin{array}{c}\n","      0 \\\\\n","      \\hline\n","      -1 \n","    \\end{array}\n","\\right] $"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rNrUCDcOHkAR"},"outputs":[],"source":["class LinearSVM:\n","    def __init__(self, C: float):\n","        \"\"\"\n","        \n","        Parameters\n","        ----------\n","        C : float\n","            Soft margin coefficient.\n","        \n","        \"\"\"\n","        self.C = C\n","        self.support = None\n","\n","    def fit(self, X: np.ndarray, y: np.ndarray) -> NoReturn:\n","        \"\"\"\n","        Обучает SVM, решая задачу оптимизации при помощи cvxopt.solvers.qp\n","        \n","        Parameters\n","        ----------\n","        X : np.ndarray\n","            Данные для обучения SVM.\n","        y : np.ndarray\n","            Бинарные метки классов для элементов X \n","            (можно считать, что равны -1 или 1). \n","        \n","        \"\"\"\n","        pass\n","\n","    def decision_function(self, X: np.ndarray) -> np.ndarray:\n","        \"\"\"\n","        Возвращает значение решающей функции.\n","        \n","        Parameters\n","        ----------\n","        X : np.ndarray\n","            Данные, для которых нужно посчитать значение решающей функции.\n","\n","        Return\n","        ------\n","        np.ndarray\n","            Значение решающей функции для каждого элемента X \n","            (т.е. то число, от которого берем знак с целью узнать класс).     \n","        \n","        \"\"\"\n","        pass\n","\n","    def predict(self, X: np.ndarray) -> np.ndarray:\n","        \"\"\"\n","        Классифицирует элементы X.\n","        \n","        Parameters\n","        ----------\n","        X : np.ndarray\n","            Данные, которые нужно классифицировать\n","\n","        Return\n","        ------\n","        np.ndarray\n","            Метка класса для каждого элемента X.   \n","        \n","        \"\"\"\n","        return np.sign(self.decision_function(X))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BmjnoPkAHkAU"},"outputs":[],"source":["X, y = generate_dataset(True)\n","svm = LinearSVM(1)\n","svm.fit(X, y)\n","visualize(svm, X, y)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AZT_t8fGHkAb"},"outputs":[],"source":["X, y = generate_dataset(False)\n","svm = LinearSVM(1)\n","svm.fit(X, y)\n","visualize(svm, X, y)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"dRzYBbW3HkAe"},"source":["### Задание 2 (2 балла)\n","Перед реализацией ядерного SVM, реализуем функции, которые строят ядра.\n","\n","#### Описание\n","`get_polynomial_kernel(power)` - возвращает полиномиальное ядро с заданной константой и степенью\n","\n","`get_gaussian_kernel(sigma=1.)` - возвращает ядро Гаусса с заданным коэффицинтом сигма"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C35q9i-XHkAf"},"outputs":[],"source":["def get_polynomial_kernel(c=1, power=2):\n","    \"Возвращает полиномиальное ядро с заданной константой и степенью\"\n","    pass\n","\n","def get_gaussian_kernel(sigma=1.):\n","    \"Возвращает ядро Гаусса с заданным коэффицинтом сигма\"\n","    pass"]},{"cell_type":"markdown","metadata":{"id":"2eRUsHsWHkAk"},"source":["### Задание 3 (2 балла)\n","Теперь перейдем к реализации самого kernel SVM.\n","\n","#### Описание\n","`fit(X, y)` - обучает kernel SVM, решая задачу оптимизации при помощи `cvxopt.solvers.qp`\n","\n","`decision_function(X)` - возвращает значение решающей функции (т.е. то число, от которого берем знак с целью узнать класс)\n","\n","#### Конструктор\n","`kernel` - ядро-функция"]},{"cell_type":"markdown","metadata":{"id":"0Iyg91H9jPkt"},"source":["### Решение с помощью QP Solver\n","\n","QP-solver решает такую задачу:\n","\n","$\\begin{cases}0.5 \\cdot x^\\text{T}Px + q^\\text{T}x\\rightarrow \\min_x\\\\Gx \\leq h\\\\Ax=b\\end{cases}$\n","\n","Будем решать двойственную задачу. Формулируется она так:\n","\n","$\\begin{cases}\\sum \\alpha_i - 0.5 \\sum \\alpha_i \\alpha_j y_i y_j K(x_i, x_j) \\rightarrow \\max_{\\alpha}\\\\ C \\geq \\alpha \\geq 0 \\\\ \\sum y_i \\alpha_i = 0 \\end{cases}$\n","\n","Сведем ее к задаче QP-solver'а:\n","\n","$ x = \\alpha \\\\ P = \n","\\left[ y_i y_j K(y_i, y_j) \\right] \\\\ \n","q = \\left[ -1\n","\\right] \\\\ \n"," G = \n","\\left[\n","    \\begin{array}{c}\n","      I\\\\\n","      \\hline\n","      -I\n","    \\end{array}\n","\\right] \\\\ h = \\left[\n","    \\begin{array}{c}\n","      C \\\\\n","      \\hline\n","      0 \n","    \\end{array}\n","\\right] \\\\\n","b = 0\\\\\n","A = y^\\text{T}$\n","\n","В таком случае решающей функцией будет:\n","\n","$a(x) = \\text{sign} (\\sum \\alpha_i y_i K(x, x_i) + w_0)$, где $w_0 = \\frac{1}{n}\\sum\\limits_{i=1}^{n}[y_i - \\sum \\alpha_j y_j K(x_i, x_j)]$"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QAv6OaZoHkAl"},"outputs":[],"source":["class KernelSVM:\n","    def __init__(self, C: float, kernel: Callable = linear_kernel):\n","        \"\"\"\n","        \n","        Parameters\n","        ----------\n","        C : float\n","            Soft margin coefficient.\n","        kernel : Callable\n","            Функция ядра.\n","        \n","        \"\"\"\n","        self.C = C\n","        self.kernel = kernel\n","        self.support = None\n","\n","    def fit(self, X: np.ndarray, y: np.ndarray) -> NoReturn:\n","        \"\"\"\n","        Обучает SVM, решая задачу оптимизации при помощи cvxopt.solvers.qp\n","        \n","        Parameters\n","        ----------\n","        X : np.ndarray\n","            Данные для обучения SVM.\n","        y : np.ndarray\n","            Бинарные метки классов для элементов X \n","            (можно считать, что равны -1 или 1). \n","        \n","        \"\"\"\n","        pass\n","\n","    def decision_function(self, X: np.ndarray) -> np.ndarray:\n","        \"\"\"\n","        Возвращает значение решающей функции.\n","        \n","        Parameters\n","        ----------\n","        X : np.ndarray\n","            Данные, для которых нужно посчитать значение решающей функции.\n","\n","        Return\n","        ------\n","        np.ndarray\n","            Значение решающей функции для каждого элемента X \n","            (т.е. то число, от которого берем знак с целью узнать класс).     \n","        \n","        \"\"\"\n","        pass\n","\n","    def predict(self, X: np.ndarray) -> np.ndarray:\n","        \"\"\"\n","        Классифицирует элементы X.\n","        \n","        Parameters\n","        ----------\n","        X : np.ndarray\n","            Данные, которые нужно классифицировать\n","\n","        Return\n","        ------\n","        np.ndarray\n","            Метка класса для каждого элемента X.   \n","        \n","        \"\"\"\n","        return np.sign(self.decision_function(X))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zni-1xfpHkAr","scrolled":false},"outputs":[],"source":["X, y = generate_dataset(True)\n","svm = KernelSVM(1, kernel=get_polynomial_kernel(1, 3))\n","svm.fit(X, y)\n","visualize(svm, X, y)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_HSzzUsgHkAv"},"outputs":[],"source":["X, y = generate_dataset(False)\n","svm = KernelSVM(1, kernel=get_polynomial_kernel(1, 3))\n","svm.fit(X, y)\n","visualize(svm, X, y)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lvN2NIefHkAx","scrolled":false},"outputs":[],"source":["X, y = generate_dataset(True)\n","svm = KernelSVM(1, kernel=get_gaussian_kernel(0.4))\n","svm.fit(X, y)\n","visualize(svm, X, y)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hsmyQUhpHkA0"},"outputs":[],"source":["X, y = generate_dataset(False)\n","svm = KernelSVM(1, kernel=get_gaussian_kernel(0.4))\n","svm.fit(X, y)\n","visualize(svm, X, y)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"H2t3tv3yHkA3"},"source":["### Задание 4 (3 балла)\n","Исследуйте и опишите влияние параметров каждого вида ядра на полученный классификатор. Что происходит при увеличении константы в полиномиальном ядре? При увеличении степени? Как влияет на результат сигма в ядре Гаусса?\n","\n","__При выполнении этого задания стоит написать код, который визуализирует классификаторы с различными ядрами__"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2q11tSF0HkA4"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lYURYC2AHkA_"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u89wg-0XHkBC"},"outputs":[],"source":[""]}],"metadata":{"colab":{"name":"hw07_task.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":0}